{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、POS Sequence Pattern 挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            text = gettext(txtDir + m + '/' + file)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            CorpusPOS(sentences)\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "(a, b, c, d, e) = calc_probabilities(cPOS)\n",
    "q1_output(a, b, c, d, e)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、 feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            name = txtDir + m + '/' + file\n",
    "            text = gettext(name)\n",
    "            words = getwords(text)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            words_s = split(words)\n",
    "            tags = [nltk.pos_tag(word) for word in words]\n",
    "            tags_s = split(tags)\n",
    "            words_l = wordlemmatize(tags_s)\n",
    "\n",
    "            F_feature = F_measure(tags_s)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            textTags = \"\"\n",
    "            for word, tag in tags_s:\n",
    "                if tag in tagList:\n",
    "                    textTags = textTags + tag + \" \"\n",
    "\n",
    "            POS_feature = []\n",
    "\n",
    "            for feature in posFeatures:\n",
    "                if feature in textTags:\n",
    "                    POS_feature.append(1)\n",
    "                else:\n",
    "                    POS_feature.append(0)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            POS_features.append(POS_feature)\n",
    "            labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(23):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(10):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(33):\n",
    "    key = 'POS_' + str(i + 1)\n",
    "    value = POS_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allofall.to_csv('allofall.csv',index = False)\n",
    "allofall = pd.read_csv('allofall.csv')\n",
    "df_per_txt = pd.read_csv('blogs_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['word ratio'], allofall['bias'] = df_per_txt['word ratio'], df_per_txt['bias']\n",
    "allofall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, target = allofall.drop(\n",
    "    columns=['name', 'label']).iloc[:].values, allofall['label'].values\n",
    "train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                    target,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=9,\n",
    "                                                    shuffle=True)\n",
    "data, target = pd.concat(\n",
    "    (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "        (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "data1 = data.iloc[:, -2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data.iloc[:, :-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.751 0.742 0.774 0.758 0.756]\n",
      "Accuracy: 0.76 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                 max_leaf_nodes=50,\n",
    "                                 n_jobs=-1)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                    data2.values,\n",
    "                                    target.values.reshape(-1, ),\n",
    "                                    cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "      (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7866666666666666"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                 max_leaf_nodes=50,\n",
    "                                 n_jobs=-1)\n",
    "rnd_clf.fit(train_X, train_y)\n",
    "y_pred = rnd_clf.predict(test_X)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7025 0.705  0.7225 0.755  0.7525]\n",
      "Accuracy: 0.73 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                 max_leaf_nodes=50,\n",
    "                                 n_jobs=-1)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target1.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.762 0.794 0.788 0.78  0.807]\n",
      "Accuracy: 0.79 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=1000,\n",
    "                                 max_leaf_nodes=50,\n",
    "                                 n_jobs=-1)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.736 0.771 0.755 0.744 0.754]\n",
      "Accuracy: 0.75 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.685 0.735 0.72  0.735 0.7  ]\n",
      "Accuracy: 0.71 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = SVC(kernel='rbf', gamma=0.1, probability=True, C=1000)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.773 0.803 0.782 0.781 0.787]\n",
      "Accuracy: 0.79 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = SVC(kernel='rbf', gamma=0.1, probability=True, C=1000)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69   0.715  0.7025 0.755  0.7125]\n",
      "Accuracy: 0.71 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = sklearn.tree.DecisionTreeClassifier(max_leaf_nodes=50)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_clf.predict(test_X)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'degree': [2, 3, 4, 5, 6]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
    "    },\n",
    "]\n",
    "\n",
    "svc_clf_gs = SVC()\n",
    "grid_search = GridSearchCV(svc_clf_gs,\n",
    "                           param_grid,\n",
    "                           cv=10,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import models, layers, regularizers, optimizers\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(65,),))\n",
    "model.add(layers.Dense(1, activation='sigmoid',))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "callbacks_list = [\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                monitor='val_acc',\n",
    "                patience=10,\n",
    "                ),\n",
    "keras.callbacks.ModelCheckpoint(\n",
    "                filepath='my_model.h5',\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                )\n",
    "]\n",
    "\n",
    "history = model.fit(data, target, batch_size=128, epochs=100, verbose = 1, \n",
    "                    validation_split=0.1, callbacks=callbacks_list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>gender</th>\n",
       "      <th>word ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.940899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.502463e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.347826e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.824561e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.165503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.419355e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.500001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.154151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.500000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.999998e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666668e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.048711e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.476777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.758065e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.177419e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.205003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.069767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.710878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.051661e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.708804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.466337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.857143e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.524928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.600000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.284394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.590909e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.640467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.774194e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.734601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.260870e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.519416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.320000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.439846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.636364e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.612434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.846154e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>0.366353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.303030e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19291</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>0.428725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19293</th>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19294</th>\n",
       "      <td>0.751326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543478e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19295</th>\n",
       "      <td>1.457325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.352941e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19296</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.076924e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.129032e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>1.384942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.082111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>0.443866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.646465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>0.551730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.021352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>1.178655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>0.287682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.714286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000002e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.888889e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>1.848927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.047619e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>0.981111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>0.662537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.605634e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>2.322195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.512195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.166667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>0.387717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.411765e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>1.170369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.824176e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>1.189811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.207639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.187500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.524332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.183206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.693050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.388889e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.333333e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias  gender    word ratio\n",
       "0      0.289545     0.0  5.000000e-01\n",
       "1      0.000000     0.0  1.000000e+00\n",
       "2      0.940899     0.0  6.502463e-01\n",
       "3      0.810930     0.0  4.347826e-01\n",
       "4      0.133531     0.0  5.000000e-01\n",
       "5      0.541787     0.0  5.824561e-01\n",
       "6      1.165503     0.0  7.419355e-01\n",
       "7      0.000000     0.0  7.500001e-01\n",
       "8      0.810930     0.0  6.000000e-01\n",
       "9      0.154151     0.0  5.500000e-01\n",
       "10     0.000000     0.0  4.000001e-01\n",
       "11     0.000000     0.0  4.999998e-07\n",
       "12     0.000000     0.0  6.666668e-01\n",
       "13     0.815642     0.0  7.048711e-01\n",
       "14     0.476777     0.0  4.758065e-01\n",
       "15     0.929878     0.0  7.177419e-01\n",
       "16     2.205003     0.0  9.069767e-01\n",
       "17     0.710878     0.0  6.051661e-01\n",
       "18     0.708804     0.0  6.530612e-01\n",
       "19     0.000000     0.0  5.000000e-01\n",
       "20     1.466337     0.0  2.857143e-01\n",
       "21     0.000000     0.0  9.500000e-01\n",
       "22     2.524928     0.0  9.600000e-01\n",
       "23     1.284394     0.0  6.590909e-01\n",
       "24     0.000000     0.0  5.000000e-01\n",
       "25     0.640467     0.0  6.774194e-01\n",
       "26     1.734601     0.0  8.260870e-01\n",
       "27     0.519416     0.0  4.320000e-01\n",
       "28     0.439846     0.0  3.636364e-01\n",
       "29     1.612434     0.0  8.846154e-01\n",
       "...         ...     ...           ...\n",
       "19290  0.366353     1.0  5.303030e-01\n",
       "19291  0.000000     1.0  5.000001e-01\n",
       "19292  0.428725     1.0  5.000000e-01\n",
       "19293  2.708050     1.0  1.000000e+00\n",
       "19294  0.751326     1.0  5.543478e-01\n",
       "19295  1.457325     1.0  7.352941e-01\n",
       "19296  0.000000     1.0  8.750000e-01\n",
       "19297  0.000000     1.0  3.076924e-01\n",
       "19298  0.346574     1.0  6.129032e-01\n",
       "19299  0.000000     1.0  7.000000e-01\n",
       "19300  1.384942     1.0  2.082111e-01\n",
       "19301  0.443866     1.0  4.646465e-01\n",
       "19302  0.551730     1.0  4.021352e-01\n",
       "19303  1.178655     1.0  6.666667e-01\n",
       "19304  0.287682     1.0  5.714286e-01\n",
       "19305  0.000000     1.0  2.000002e-01\n",
       "19306  2.639057     1.0  8.888889e-01\n",
       "19307  1.848927     1.0  9.047619e-01\n",
       "19308  0.000000     1.0  8.666667e-01\n",
       "19309  0.981111     1.0  6.530612e-01\n",
       "19310  0.662537     1.0  7.605634e-01\n",
       "19311  2.322195     1.0  9.512195e-01\n",
       "19312  0.000000     1.0  9.166667e-01\n",
       "19313  0.387717     1.0  4.411765e-01\n",
       "19314  1.170369     1.0  7.824176e-01\n",
       "19315  1.189811     1.0  7.750000e-01\n",
       "19316  0.207639     1.0  7.187500e-01\n",
       "19317  0.524332     1.0  6.183206e-01\n",
       "19318  0.693050     1.0  6.388889e-01\n",
       "19319  2.564949     1.0  8.333333e-01\n",
       "\n",
       "[19320 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_txt = pd.read_csv('blogs_genderbias.csv')\n",
    "df_per_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall.to_csv('blogs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './2000novel/female/'\n",
    "    else:\n",
    "        txtDir = './2000novel/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(blogs_gender))\n",
    "    for m in blogs_gender:\n",
    "        text = gettext(txtDir + m)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        CorpusPOS(sentences)\n",
    "\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "\n",
    "cPOS_new = []\n",
    "for sent in cPOS:\n",
    "    sent_new = re.sub(r'[^\\w\\s]','',sent)\n",
    "    cPOS_new.append(sent_new)\n",
    "\n",
    "(a, b, c, d, e, f, g) = calc_probabilities(cPOS_new)\n",
    "q1_output(a, b, c, d, e, f, g)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'CC',\n",
       " 'NNS',\n",
       " 'NNP',\n",
       " 'IN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'PRP',\n",
       " 'VB',\n",
       " 'VBD',\n",
       " 'RB',\n",
       " 'RP',\n",
       " 'JJ',\n",
       " 'VBN']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./5000/female/\n",
      "Files: 2500\n",
      "Processing gender: ./5000/male/\n",
      "Files: 2500\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './5000/female/'\n",
    "    else:\n",
    "        txtDir = './5000/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(blogs_gender))\n",
    "    for m in blogs_gender:\n",
    "        name = txtDir + m\n",
    "        text = gettext(name)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        words_l = wordlemmatize(tags)\n",
    "\n",
    "        F_feature = F_measure(tags)\n",
    "        GRF_feature = Gender_Preferential_Features(words_l)\n",
    "        WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "        #textTags = \"\"\n",
    "        #for word, tag in tags_s:\n",
    "        #    if tag in tagList:\n",
    "        #        textTags = textTags + tag + \" \"\n",
    "\n",
    "        #POS_feature = []\n",
    "\n",
    "        #for feature in posFeatures:\n",
    "        #    if feature in textTags:\n",
    "        #        POS_feature.append(1)\n",
    "        #    else:\n",
    "        #        POS_feature.append(0)\n",
    "        names.append(name)\n",
    "        F_features.append(F_feature)\n",
    "        GRF_features.append(GRF_feature)\n",
    "        WC_features.append(WC_feature)\n",
    "        #POS_features.append(POS_feature)\n",
    "        labels.append(gender)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsingle(features, n):\n",
    "    single = []\n",
    "    for item in features:\n",
    "        single.append(item[n])\n",
    "    return single\n",
    "\n",
    "\n",
    "WC_features_l = []\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "GRF_features_l = []\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "#POS_features_l = []\n",
    "#for i in range(len(POS_features[0])):\n",
    "#    n = i\n",
    "#    POS_features_l.append(getsingle(POS_features, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "#for i in range(len(POS_features[0])):\n",
    "#    key = 'POS_' + str(i + 1)\n",
    "#    value = POS_features_l[i]\n",
    "#    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_5000.csv',index = False)\n",
    "#allofall = pd.read_csv('allofall.csv')\n",
    "#df_per_txt = pd.read_csv('blogs_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_per_txt = pd.read_csv('5000_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['bias'], allofall['word ratio'] = df_per_txt['bias'], df_per_txt['word ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall.to_csv('5000_features.csv',index=False)\n",
    "#allofall = pd.read_csv('5000_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./5000/female/\n",
      "Files: 2500\n",
      "Processing gender: ./5000/male/\n",
      "Files: 2500\n"
     ]
    }
   ],
   "source": [
    "lengths = []\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './5000/female/'\n",
    "    else:\n",
    "        txtDir = './5000/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(blogs_gender))\n",
    "    for m in blogs_gender:\n",
    "        text = gettext(txtDir + m)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        length = len(words)\n",
    "        \n",
    "        lengths.append(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall = pd.read_csv('5000_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['word count'] = lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72007.5714"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allofall['word count'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
