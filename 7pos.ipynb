{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "一、函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from sklearn.svm import SVR, SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "def gettext(filename):\n",
    "    handle = open(filename, 'r', encoding='UTF-8')\n",
    "    text = handle.read()\n",
    "    handle.close()\n",
    "    return text\n",
    "\n",
    "\n",
    "def wordlemmatize(tags):\n",
    "    from nltk.stem import WordNetLemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words_l = []\n",
    "    for tag in tags:\n",
    "        if tag[1] and tag[1] in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
    "            words_l.append(lemmatizer.lemmatize(tag[0], pos='n'))\n",
    "        elif tag[1] and tag[1] in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
    "            words_l.append(lemmatizer.lemmatize(tag[0], pos='v'))\n",
    "        elif tag[1] and tag[1] in ['JJ', 'JJR', 'JJS']:\n",
    "            words_l.append(lemmatizer.lemmatize(tag[0], pos='a'))\n",
    "        elif tag[1] and tag[1] in ['RB', 'RBR', 'RBS']:\n",
    "            words_l.append(lemmatizer.lemmatize(tag[0], pos='r'))\n",
    "        else:\n",
    "            words_l.append(tag[0])\n",
    "    return words_l\n",
    "\n",
    "\n",
    "def F_measure(tags_s):\n",
    "    Flist = {\n",
    "        'noum': ['NN', 'NNS', 'NNP', 'NNPS'],\n",
    "        'adj': ['JJ', 'JJR', 'JJS'],\n",
    "        'prep': ['IN'],\n",
    "        'art': ['CD'],\n",
    "        'pron': ['PRP', 'WP'],\n",
    "        'verb': ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ'],\n",
    "        'adv': ['RB', 'RBR', 'RBS'],\n",
    "        'int': ['UH']\n",
    "    }\n",
    "    tagshapelist = [0] * len(tags_s)\n",
    "\n",
    "    for i, tag in enumerate(tags_s):\n",
    "        tagshapelist[i] = tag[1]\n",
    "    ff = dict(Counter(tagshapelist))\n",
    "\n",
    "    a = 0\n",
    "    b = 0\n",
    "    for i, poslist in enumerate(Flist.values()):\n",
    "        if i < 4:\n",
    "            for pos in poslist:\n",
    "                if pos in ff.keys():\n",
    "                    a += ff[pos]\n",
    "        if i >= 4:\n",
    "            for pos in poslist:\n",
    "                if pos in ff.keys():\n",
    "                    b += ff[pos]\n",
    "    F_feature = 0.5 * (a - b + 100)\n",
    "    return F_feature\n",
    "\n",
    "\n",
    "def Gender_Preferential_Features(words_l):\n",
    "    GPFlist = ['able', 'al', 'ful', 'ible', 'ic', 'ive', 'less', 'ly', 'ous']\n",
    "    GPF_feature = [0] * (len(GPFlist) + 1)\n",
    "\n",
    "    for i, trigger in enumerate(GPFlist):\n",
    "        flag = [0] * len(words_l)\n",
    "        for j, word in enumerate(words_l):\n",
    "            flag[j] = word.endswith(trigger)\n",
    "        GPF_feature[i] = sum(flag)\n",
    "    GPF_feature[-1] = words.count('sorry') + words.count('sry')\n",
    "    if sum(GPF_feature) != 0:\n",
    "        GPF_feature = np.array(GPF_feature) / sum(GPF_feature)\n",
    "    return GPF_feature\n",
    "\n",
    "\n",
    "def Word_Classes_Feature(words_l):\n",
    "    classlist = {\n",
    "        'Conversation': [\n",
    "            'know', 'people', 'think', 'person', 'tell', 'feel', 'friends',\n",
    "            'talk', 'new', 'talking', 'mean', 'ask', 'understand', 'feelings',\n",
    "            'care', 'thinking', 'friend', 'relationship', 'realize',\n",
    "            'question', 'answer', 'saying'\n",
    "        ],\n",
    "        'AtHome': [\n",
    "            'woke', 'home', 'sleep', 'today', 'eat', 'tired', 'wake', 'watch',\n",
    "            'watched', 'dinner', 'ate', 'bed', 'day', 'house', 'tv', 'early',\n",
    "            'boring', 'yesterday', 'watching', 'sit'\n",
    "        ],\n",
    "        'Family': [\n",
    "            'years', 'family', 'mother', 'children', 'father', 'kids',\n",
    "            'parents', 'old', 'year', 'child', 'son', 'married', 'sister',\n",
    "            'dad', 'brother', 'moved', 'age', 'young', 'months', 'three',\n",
    "            'wife', 'living', 'college', 'four', 'high', 'five', 'died', 'six',\n",
    "            'baby', 'boy', 'spend', 'christmas'\n",
    "        ],\n",
    "        'Time': [\n",
    "            'friday', 'saturday', 'weekend', 'week', 'sunday', 'night',\n",
    "            'monday', 'tuesday', 'thursday', 'wednesday', 'morning',\n",
    "            'tomorrow', 'tonight', 'evening', 'days', 'afternoon', 'weeks',\n",
    "            'hours', 'july', 'busy', 'meeting', 'hour', 'month', 'june'\n",
    "        ],\n",
    "        'Work': [\n",
    "            'work', 'working', 'job', 'trying', 'right', 'met', 'figure',\n",
    "            'meet', 'start', 'better', 'starting', 'try', 'worked', 'idea'\n",
    "        ],\n",
    "        'PastActions': [\n",
    "            'said', 'asked', 'told', 'looked', 'walked', 'called', 'talked',\n",
    "            'wanted', 'kept', 'took', 'sat', 'gave', 'knew', 'felt', 'turned',\n",
    "            'stopped', 'saw', 'ran', 'tried', 'picked', 'left', 'ended'\n",
    "        ],\n",
    "        'Games': [\n",
    "            'game', 'games', 'team', 'win', 'play', 'played', 'playing', 'won',\n",
    "            'season', 'beat', 'final', 'two', 'hit', 'first', 'video',\n",
    "            'second', 'run', 'star', 'third', 'shot', 'table', 'round', 'ten',\n",
    "            'chance', 'club', 'big', 'straight'\n",
    "        ],\n",
    "        'Internet': [\n",
    "            'site', 'email', 'page', 'please', 'website', 'web', 'post',\n",
    "            'link', 'check', 'blog', 'mail', 'information', 'free', 'send',\n",
    "            'comments', 'comment', 'using', 'internet', 'online', 'name',\n",
    "            'service', 'list', 'computer', 'add', 'thanks', 'update', 'message'\n",
    "        ],\n",
    "        'Location': [\n",
    "            'street', 'place', 'town', 'road', 'city', 'walking', 'trip',\n",
    "            'headed', 'front', 'car', 'beer', 'apartment', 'bus', 'area',\n",
    "            'park', 'building', 'walk', 'small', 'places', 'ride', 'driving',\n",
    "            'looking', 'local', 'sitting', 'drive', 'bar', 'bad', 'standing',\n",
    "            'floor', 'weather', 'beach', 'view'\n",
    "        ],\n",
    "        'Fun': [\n",
    "            'fun', 'im', 'cool', 'mom', 'summer', 'awesome', 'lol', 'stuff',\n",
    "            'pretty', 'ill', 'mad', 'funny', 'weird'\n",
    "        ],\n",
    "        'Food/Clothes': [\n",
    "            'food', 'eating', 'weight', 'lunch', 'water', 'hair', 'life',\n",
    "            'white', 'wearing', 'color', 'ice', 'red', 'fat', 'body', 'black',\n",
    "            'clothes', 'hot', 'drink', 'wear', 'blue', 'minutes', 'shirt',\n",
    "            'green', 'coffee', 'total', 'store', 'shopping'\n",
    "        ],\n",
    "        'Poetic': [\n",
    "            'eyes', 'heart', 'soul', 'pain', 'light', 'deep', 'smile',\n",
    "            'dreams', 'dark', 'hold', 'hands', 'head', 'hand', 'alone', 'sun',\n",
    "            'dream', 'mind', 'cold', 'fall', 'air', 'voice', 'touch', 'blood',\n",
    "            'feet', 'words', 'hear', 'rain', 'mouth'\n",
    "        ],\n",
    "        'Books/Movies': [\n",
    "            'book', 'read', 'reading', 'books', 'story', 'writing', 'written',\n",
    "            'movie', 'stories', 'movies', 'film', 'write', 'character', 'fact',\n",
    "            'thoughts', 'title', 'short', 'take', 'wrote'\n",
    "        ],\n",
    "        'Religion': [\n",
    "            'god', 'jesus', 'lord', 'church', 'earth', 'world', 'word',\n",
    "            'lives', 'power', 'human', 'believe', 'given', 'truth', 'thank',\n",
    "            'death', 'evil', 'own', 'peace', 'speak', 'bring', 'truly'\n",
    "        ],\n",
    "        'Romance': [\n",
    "            'forget', 'forever', 'remember', 'gone', 'true', 'face', 'spent',\n",
    "            'times', 'love', 'cry', 'hurt', 'wish', 'loved'\n",
    "        ],\n",
    "        'Swearing': [\n",
    "            'shit', 'fuck', 'fucking', 'ass', 'bitch', 'damn', 'hell', 'sucks',\n",
    "            'stupid', 'hate', 'drunk', 'crap', 'kill', 'guy', 'gay', 'kid',\n",
    "            'sex', 'crazy'\n",
    "        ],\n",
    "        'Politics': [\n",
    "            'bush', 'president', 'Iraq', 'kerry', 'war', 'american',\n",
    "            'political', 'states', 'america', 'country', 'government', 'john',\n",
    "            'national', 'news', 'state', 'support', 'issues', 'article',\n",
    "            'michael', 'bill', 'report', 'public', 'issue', 'history', 'party',\n",
    "            'york', 'law', 'major', 'act', 'fight', 'poor'\n",
    "        ],\n",
    "        'Music': [\n",
    "            'music', 'songs', 'song', 'band', 'cd', 'rock', 'listening',\n",
    "            'listen', 'show', 'favorite', 'radio', 'sound', 'heard', 'shows',\n",
    "            'sounds', 'amazing', 'dance'\n",
    "        ],\n",
    "        'School': [\n",
    "            'school', 'teacher', 'class', 'study', 'test', 'finish', 'english',\n",
    "            'students', 'period', 'paper', 'pass'\n",
    "        ],\n",
    "        'Business': [\n",
    "            'system', 'based', 'process', 'business', 'control', 'example',\n",
    "            'personal', 'experience', 'general'\n",
    "        ],\n",
    "        'Positive': [\n",
    "            'absolutely', 'abundance', 'ace', 'active', 'admirable', 'adore',\n",
    "            'agree', 'amazing', 'appealing', 'attraction', 'bargain',\n",
    "            'beaming', 'beautiful', 'best', 'better', 'boost', 'breakthrough',\n",
    "            'breeze', 'brilliant', 'brimming', 'charming', 'clean', 'clear',\n",
    "            'colorful', 'compliment', 'confidence', 'cool', 'courteous',\n",
    "            'cuddly', 'dazzling', 'delicious', 'delightful', 'dynamic', 'easy',\n",
    "            'ecstatic', 'efficient', 'enhance', 'enjoy', 'enormous',\n",
    "            'excellent', 'exotic', 'expert', 'exquisite', 'flair', 'free',\n",
    "            'generous', 'genius', 'great', 'graceful', 'heavenly', 'ideal',\n",
    "            'immaculate', 'impressive', 'incredible', 'inspire', 'luxurious',\n",
    "            'outstanding', 'royal', 'speed', 'splendid', 'spectacular',\n",
    "            'superb', 'sweet', 'sure', 'supreme', 'terrific', 'treat',\n",
    "            'treasure', 'ultra', 'unbeatable', 'ultimate', 'unique', 'wow',\n",
    "            'zest'\n",
    "        ],\n",
    "        'Negative': [\n",
    "            'wrong', 'stupid', 'bad', 'evil', 'dumb', 'foolish', 'grotesque',\n",
    "            'harm', 'fear', 'horrible', 'idiot', 'lame', 'mean', 'poor',\n",
    "            'heinous', 'hideous', 'deficient', 'petty', 'awful', 'hopeless',\n",
    "            'fool', 'risk', 'immoral', 'risky', 'spoil', 'spoiled', 'malign',\n",
    "            'vicious', 'wicked', 'fright', 'ugly', 'atrocious', 'moron',\n",
    "            'hate', 'spiteful', 'meager', 'malicious', 'lacking'\n",
    "        ],\n",
    "        'Emotion': [\n",
    "            'aggressive', 'alienated', 'angry', 'annoyed', 'anxious',\n",
    "            'careful', 'cautious', 'confused', 'curious', 'depressed',\n",
    "            'determined', 'disappointed', 'discouraged', 'disgusted',\n",
    "            'ecstatic', 'embarrassed', 'enthusiastic', 'envious', 'excited',\n",
    "            'exhausted', 'frightened', 'frustrated', 'guilty', 'happy',\n",
    "            'helpless', 'hopeful', 'hostile', 'humiliated', 'hurt',\n",
    "            'hysterical', 'innocent', 'interested', 'jealous', 'lonely',\n",
    "            'mischievous', 'miserable', 'optimistic', 'paranoid', 'peaceful',\n",
    "            'proud', 'puzzled', 'regretful', 'relieved', 'sad', 'satisfied',\n",
    "            'shocked', 'shy', 'sorry', 'surprised', 'suspicious', 'thoughtful',\n",
    "            'undecided', 'withdrawn'\n",
    "        ]\n",
    "    }\n",
    "    WC_feature = [0] * len(classlist)\n",
    "\n",
    "    for i, ws in enumerate(classlist.values()):\n",
    "        for w in ws:\n",
    "            WC_feature[i] += words_l.count(w)\n",
    "    if sum(WC_feature) != 0:\n",
    "        WC_feature = np.array(WC_feature) / sum(WC_feature)\n",
    "    return WC_feature\n",
    "\n",
    "\n",
    "def CorpusPOS(sentences):\n",
    "    posTagList = [\n",
    "        'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW',\n",
    "        'CD', 'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT',\n",
    "        'WP', 'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB',\n",
    "        'RBR', 'RBS', 'RP', 'WRB', 'UH', '.'\n",
    "    ]\n",
    "    outfile = open('CorpusPOS.txt', 'w')\n",
    "    for sentence in sentences:\n",
    "        tagSentence = \"\"\n",
    "        tokensWord = nltk.word_tokenize(sentence)\n",
    "        textToken = nltk.Text(tokensWord)\n",
    "        tags = nltk.pos_tag(tokensWord)\n",
    "\n",
    "        for a, b in tags:\n",
    "            if b in posTagList:\n",
    "                tagSentence = tagSentence + b + \" \"\n",
    "        tagSentence = tagSentence + \"\\n\"\n",
    "        outfile.write(tagSentence)\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def calc_probabilities(cPOS):\n",
    "    from nltk import ngrams\n",
    "\n",
    "    unigram_p = {}\n",
    "    bigram_p = {}\n",
    "    trigram_p = {}\n",
    "    fourgram_p = {}\n",
    "    fivegram_p = {}\n",
    "    sixgram_p = {}\n",
    "    sevengram_p = {}\n",
    "\n",
    "    unigram = {}\n",
    "    bigram = {}\n",
    "    trigram = {}\n",
    "    fourgram = {}\n",
    "    fivegram = {}\n",
    "    sixgram = {}\n",
    "    sevengram = {}\n",
    "    uni_count = biCount = triCount = fourCount = fiveCount = sixCount = sevenCount = 0\n",
    "\n",
    "    for sentence in cPOS:\n",
    "        tokens = sentence.split()\n",
    "\n",
    "        for word in tokens:\n",
    "            uni_count += 1\n",
    "\n",
    "            if word in unigram:\n",
    "                unigram[word] += 1\n",
    "            else:\n",
    "                unigram[word] = 1\n",
    "\n",
    "        bigram_tuples = tuple(nltk.bigrams(tokens))\n",
    "        for item in bigram_tuples:\n",
    "            biCount += 1\n",
    "            if item in bigram:\n",
    "                bigram[item] += 1\n",
    "            else:\n",
    "                bigram[item] = 1\n",
    "\n",
    "        trigram_tuples = tuple(nltk.trigrams(tokens))\n",
    "        for item in trigram_tuples:\n",
    "            triCount += 1\n",
    "            if item in trigram:\n",
    "                trigram[item] += 1\n",
    "            else:\n",
    "                trigram[item] = 1\n",
    "\n",
    "        fourgram_tuples = ngrams(tokens, 4)\n",
    "        for item in fourgram_tuples:\n",
    "            fourCount += 1\n",
    "            if item in fourgram:\n",
    "                fourgram[item] += 1\n",
    "            else:\n",
    "                fourgram[item] = 1\n",
    "\n",
    "        fivegram_tuples = ngrams(tokens, 5)\n",
    "        for item in fivegram_tuples:\n",
    "            fiveCount += 1\n",
    "            if item in fivegram:\n",
    "                fivegram[item] += 1\n",
    "            else:\n",
    "                fivegram[item] = 1\n",
    "\n",
    "        sixgram_tuples = ngrams(tokens, 6)\n",
    "        for item in sixgram_tuples:\n",
    "            sixCount += 1\n",
    "            if item in sixgram:\n",
    "                sixgram[item] += 1\n",
    "            else:\n",
    "                sixgram[item] = 1\n",
    "\n",
    "        sevengram_tuples = ngrams(tokens, 7)\n",
    "        for item in sevengram_tuples:\n",
    "            sevenCount += 1\n",
    "            if item in sevengram:\n",
    "                sevengram[item] += 1\n",
    "            else:\n",
    "                sevengram[item] = 1\n",
    "\n",
    "    # calculate unigram probability\n",
    "    for word in unigram:\n",
    "        temp = [word]\n",
    "        unigram_p[tuple(temp)] = (float(unigram[word]) / uni_count)\n",
    "\n",
    "    # calculate bigram probability\n",
    "    for word in bigram:\n",
    "        bigram_p[tuple(word)] = (float(bigram[word]) / biCount)\n",
    "\n",
    "    # calculate trigram probability\n",
    "    for word in trigram:\n",
    "        trigram_p[tuple(word)] = (float(trigram[word]) / triCount)\n",
    "\n",
    "    # calculate fourgram probability\n",
    "    for word in fourgram:\n",
    "        fourgram_p[tuple(word)] = (float(fourgram[word]) / fourCount)\n",
    "\n",
    "    # calculate fivegram probability\n",
    "    for word in fivegram:\n",
    "        fivegram_p[tuple(word)] = (float(fivegram[word]) / fiveCount)\n",
    "\n",
    "    for word in sixgram:\n",
    "        sixgram_p[tuple(word)] = (float(sixgram[word]) / sixCount)\n",
    "\n",
    "    for word in sevengram:\n",
    "        sevengram_p[tuple(word)] = (float(sevengram[word]) / sevenCount)\n",
    "\n",
    "    return unigram_p, bigram_p, trigram_p, fourgram_p, fivegram_p, sixgram_p, sevengram_p\n",
    "\n",
    "\n",
    "def q1_output(unigrams, bigrams, trigrams, fourgrams, fivegrams, sixgrams,\n",
    "              sevengrams):\n",
    "    #output probabilities\n",
    "    outfile = open('probabilities.txt', 'w')\n",
    "    for unigram in unigrams:\n",
    "        outfile.write(unigram[0] + ':' + str(unigrams[unigram]) + '\\n')\n",
    "    for bigram in bigrams:\n",
    "        outfile.write(bigram[0] + ' ' + bigram[1] + ':' +\n",
    "                      str(bigrams[bigram]) + '\\n')\n",
    "    for trigram in trigrams:\n",
    "        outfile.write(trigram[0] + ' ' + trigram[1] + ' ' + trigram[2] + ':' +\n",
    "                      str(trigrams[trigram]) + '\\n')\n",
    "\n",
    "    for fourgram in fourgrams:\n",
    "        outfile.write(fourgram[0] + ' ' + fourgram[1] + ' ' + fourgram[2] +\n",
    "                      ' ' + fourgram[3] + ':' + str(fourgrams[fourgram]) +\n",
    "                      '\\n')\n",
    "\n",
    "    for fivegram in fivegrams:\n",
    "        outfile.write(fivegram[0] + ' ' + fivegram[1] + ' ' + fivegram[2] +\n",
    "                      ' ' + fivegram[3] + ' ' + fivegram[4] + ':' +\n",
    "                      str(fivegrams[fivegram]) + '\\n')\n",
    "\n",
    "    for sixgram in sixgrams:\n",
    "        outfile.write(sixgram[0] + ' ' + sixgram[1] + ' ' + sixgram[2] + ' ' +\n",
    "                      sixgram[3] + ' ' + sixgram[4] + ' ' + sixgram[5] + ':' +\n",
    "                      str(sixgrams[sixgram]) + '\\n')\n",
    "\n",
    "    for sevengram in sevengrams:\n",
    "        outfile.write(sevengram[0] + ' ' + sevengram[1] + ' ' + sevengram[2] +\n",
    "                      ' ' + sevengram[3] + ' ' + sevengram[4] + ' ' +\n",
    "                      sevengram[5] + ' ' + sevengram[6] + ':' +\n",
    "                      str(sevengrams[sevengram]) + '\\n')\n",
    "\n",
    "    outfile.close()\n",
    "\n",
    "\n",
    "def prob(sequence):\n",
    "    if sequence in Prob.keys():\n",
    "        return Prob[sequence]\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def fairSCP(sequence):\n",
    "    numerator = prob(sequence) * prob(sequence)\n",
    "    sequence = sequence.split()\n",
    "\n",
    "    denominator = 0\n",
    "\n",
    "    for j in range(1, len(sequence)):\n",
    "        seq1 = \"\"\n",
    "        seq2 = \"\"\n",
    "        cnt = 1\n",
    "\n",
    "        for tag in sequence:\n",
    "            if cnt <= j:\n",
    "                seq1 = seq1 + tag + \" \"\n",
    "                cnt += 1\n",
    "            else:\n",
    "                seq2 = seq2 + tag + \" \"\n",
    "\n",
    "        seq2 = seq2[:-1]\n",
    "        seq1 = seq1[:-1]\n",
    "\n",
    "        denominator += prob(seq1) * prob(seq2)\n",
    "\n",
    "    denominator = denominator * 1.0 / (len(sequence) - 1)\n",
    "\n",
    "    if denominator == 0:\n",
    "        return 0.0\n",
    "\n",
    "    SCP = numerator * 1.0 / denominator\n",
    "\n",
    "    return SCP\n",
    "\n",
    "\n",
    "def candidateGen(Fk):\n",
    "    Ck = []\n",
    "\n",
    "    for item in Fk:\n",
    "        for tag in tagList:\n",
    "            itemTemp = item + \" \" + tag\n",
    "            Ck.append(itemTemp)\n",
    "\n",
    "    return Ck\n",
    "\n",
    "\n",
    "def minePOSPats(cPOS):\n",
    "    minSup = 0.3\n",
    "    minAdherence = 0.2\n",
    "    C = [{} for i in range(7)]\n",
    "    F = [[] for i in range(7)]\n",
    "    SP = [[] for i in range(7)]\n",
    "    Cand = [[] for i in range(7)]\n",
    "\n",
    "    Doc = cPOS\n",
    "    n = len(Doc)\n",
    "\n",
    "    for post in Doc:\n",
    "        for tag in tagList:\n",
    "            if tag in post:\n",
    "                if tag in C[0].keys():\n",
    "                    C[0][tag] += 1\n",
    "                else:\n",
    "                    C[0][tag] = 1\n",
    "\n",
    "    for a in C[0]:\n",
    "        if C[0][a] * 1.0 / n >= minSup:\n",
    "            F[0].append(a)\n",
    "\n",
    "    SP[0] = F[0]\n",
    "    temp = {}\n",
    "    for k in range(1, 7):\n",
    "        Cand[k] = candidateGen(F[k - 1])\n",
    "        for post in Doc:\n",
    "            for candidate in Cand[k]:\n",
    "                if candidate in post:\n",
    "                    if candidate in C[k].keys():\n",
    "                        C[k][candidate] += 1\n",
    "                    else:\n",
    "                        C[k][candidate] = 1\n",
    "\n",
    "        for a in C[k]:\n",
    "            if C[k][a] * 1.0 / n >= minSup:\n",
    "                F[k].append(a)\n",
    "\n",
    "        for a in F[k]:\n",
    "            if fairSCP(a) >= minAdherence:\n",
    "                SP[k].append(a)\n",
    "\n",
    "    SPFinal = []\n",
    "    SPFinal = SP[0] + SP[1] + SP[2] + SP[3] + SP[4] + SP[5] + SP[6]\n",
    "\n",
    "    return SPFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "二、POS Sequence Pattern 挖掘"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./postprocess_blogs/blogs/female/\n",
      "Processing:  Chemicals\n",
      "Files: 23\n",
      "Processing:  Fashion\n",
      "Files: 73\n",
      "Processing:  Banking\n",
      "Files: 47\n",
      "Processing:  Construction\n",
      "Files: 22\n",
      "Processing:  Student\n",
      "Files: 2479\n",
      "Processing:  InvestmentBanking\n",
      "Files: 10\n",
      "Processing:  Engineering\n",
      "Files: 70\n",
      "Processing:  Arts\n",
      "Files: 419\n",
      "Processing:  Technology\n",
      "Files: 180\n",
      "Processing:  Consulting\n",
      "Files: 73\n",
      "Processing:  Internet\n",
      "Files: 101\n",
      "Processing:  Sports-Recreation\n",
      "Files: 36\n",
      "Processing:  Religion\n",
      "Files: 43\n",
      "Processing:  BusinessServices\n",
      "Files: 81\n",
      "Processing:  Automotive\n",
      "Files: 17\n",
      "Processing:  Tourism\n",
      "Files: 54\n",
      "Processing:  Non-Profit\n",
      "Files: 194\n",
      "Processing:  Museums-Libraries\n",
      "Files: 33\n",
      "Processing:  indUnk\n",
      "Files: 3961\n",
      "Processing:  Communications-Media\n",
      "Files: 209\n",
      "Processing:  Military\n",
      "Files: 32\n",
      "Processing:  Telecommunications\n",
      "Files: 40\n",
      "Processing:  Advertising\n",
      "Files: 75\n",
      "Processing:  Biotech\n",
      "Files: 20\n",
      "Processing:  Science\n",
      "Files: 84\n",
      "Processing:  Environment\n",
      "Files: 14\n",
      "Processing:  Government\n",
      "Files: 95\n",
      "Processing:  Law\n",
      "Files: 109\n",
      "Processing:  Transportation\n",
      "Files: 35\n",
      "Processing:  Marketing\n",
      "Files: 107\n",
      "Processing:  LawEnforcement-Security\n",
      "Files: 26\n",
      "Processing:  Publishing\n",
      "Files: 79\n",
      "Processing:  Accounting\n",
      "Files: 74\n",
      "Processing:  Education\n",
      "Files: 570\n",
      "Processing:  RealEstate\n",
      "Files: 39\n",
      "Processing:  Manufacturing\n",
      "Files: 24\n",
      "Processing:  Agriculture\n",
      "Files: 20\n",
      "Processing:  HumanResources\n",
      "Files: 53\n",
      "Processing:  Maritime\n",
      "Files: 4\n",
      "Processing:  Architecture\n",
      "Files: 35\n",
      "Processing gender: ./postprocess_blogs/blogs/male/\n",
      "Processing:  Chemicals\n",
      "Files: 39\n",
      "Processing:  Fashion\n",
      "Files: 25\n",
      "Processing:  Banking\n",
      "Files: 65\n",
      "Processing:  Construction\n",
      "Files: 33\n",
      "Processing:  Student\n",
      "Files: 2641\n",
      "Processing:  InvestmentBanking\n",
      "Files: 23\n",
      "Processing:  Engineering\n",
      "Files: 242\n",
      "Processing:  Arts\n",
      "Files: 302\n",
      "Processing:  Technology\n",
      "Files: 763\n",
      "Processing:  Consulting\n",
      "Files: 118\n",
      "Processing:  Internet\n",
      "Files: 296\n",
      "Processing:  Sports-Recreation\n",
      "Files: 54\n",
      "Processing:  Religion\n",
      "Files: 96\n",
      "Processing:  BusinessServices\n",
      "Files: 82\n",
      "Processing:  Automotive\n",
      "Files: 37\n",
      "Processing:  Tourism\n",
      "Files: 40\n",
      "Processing:  Non-Profit\n",
      "Files: 178\n",
      "Processing:  Museums-Libraries\n",
      "Files: 22\n",
      "Processing:  indUnk\n",
      "Files: 2866\n",
      "Processing:  Communications-Media\n",
      "Files: 270\n",
      "Processing:  Military\n",
      "Files: 84\n",
      "Processing:  Telecommunications\n",
      "Files: 79\n",
      "Processing:  Advertising\n",
      "Files: 70\n",
      "Processing:  Biotech\n",
      "Files: 37\n",
      "Processing:  Science\n",
      "Files: 100\n",
      "Processing:  Environment\n",
      "Files: 14\n",
      "Processing:  Government\n",
      "Files: 141\n",
      "Processing:  Law\n",
      "Files: 88\n",
      "Processing:  Transportation\n",
      "Files: 56\n",
      "Processing:  Marketing\n",
      "Files: 73\n",
      "Processing:  LawEnforcement-Security\n",
      "Files: 31\n",
      "Processing:  Publishing\n",
      "Files: 71\n",
      "Processing:  Accounting\n",
      "Files: 31\n",
      "Processing:  Education\n",
      "Files: 410\n",
      "Processing:  RealEstate\n",
      "Files: 16\n",
      "Processing:  Manufacturing\n",
      "Files: 63\n",
      "Processing:  Agriculture\n",
      "Files: 16\n",
      "Processing:  HumanResources\n",
      "Files: 41\n",
      "Processing:  Maritime\n",
      "Files: 13\n",
      "Processing:  Architecture\n",
      "Files: 34\n"
     ]
    }
   ],
   "source": [
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            text = gettext(txtDir + m + '/' + file)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            CorpusPOS(sentences)\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "(a, b, c, d, e) = calc_probabilities(cPOS)\n",
    "q1_output(a, b, c, d, e)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NN',\n",
       " 'CC',\n",
       " 'PDT',\n",
       " 'NNS',\n",
       " 'FW',\n",
       " 'CD',\n",
       " 'JJ',\n",
       " 'JJR',\n",
       " 'JJS',\n",
       " 'IN',\n",
       " 'TO',\n",
       " 'DT',\n",
       " 'EX',\n",
       " 'PRP',\n",
       " 'PRP$',\n",
       " 'WDT',\n",
       " 'WP',\n",
       " 'WP$',\n",
       " 'MD',\n",
       " 'VB',\n",
       " 'VBZ',\n",
       " 'VBP',\n",
       " 'VBD',\n",
       " 'VBN',\n",
       " 'VBG',\n",
       " 'RB',\n",
       " 'RBR',\n",
       " 'RBS',\n",
       " 'RP',\n",
       " 'WRB',\n",
       " 'UH',\n",
       " 'TO VB',\n",
       " 'RBR DT NN JJ EX']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "posFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "三、 feature engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./postprocess_blogs/blogs/female/\n",
      "Processing:  Chemicals\n",
      "Files: 23\n",
      "Processing:  Fashion\n",
      "Files: 73\n",
      "Processing:  Banking\n",
      "Files: 47\n",
      "Processing:  Construction\n",
      "Files: 22\n",
      "Processing:  Student\n",
      "Files: 2479\n",
      "Processing:  InvestmentBanking\n",
      "Files: 10\n",
      "Processing:  Engineering\n",
      "Files: 70\n",
      "Processing:  Arts\n",
      "Files: 419\n",
      "Processing:  Technology\n",
      "Files: 180\n",
      "Processing:  Consulting\n",
      "Files: 73\n",
      "Processing:  Internet\n",
      "Files: 101\n",
      "Processing:  Sports-Recreation\n",
      "Files: 36\n",
      "Processing:  Religion\n",
      "Files: 43\n",
      "Processing:  BusinessServices\n",
      "Files: 81\n",
      "Processing:  Automotive\n",
      "Files: 17\n",
      "Processing:  Tourism\n",
      "Files: 54\n",
      "Processing:  Non-Profit\n",
      "Files: 194\n",
      "Processing:  Museums-Libraries\n",
      "Files: 33\n",
      "Processing:  indUnk\n",
      "Files: 3961\n",
      "Processing:  Communications-Media\n",
      "Files: 209\n",
      "Processing:  Military\n",
      "Files: 32\n",
      "Processing:  Telecommunications\n",
      "Files: 40\n",
      "Processing:  Advertising\n",
      "Files: 75\n",
      "Processing:  Biotech\n",
      "Files: 20\n",
      "Processing:  Science\n",
      "Files: 84\n",
      "Processing:  Environment\n",
      "Files: 14\n",
      "Processing:  Government\n",
      "Files: 95\n",
      "Processing:  Law\n",
      "Files: 109\n",
      "Processing:  Transportation\n",
      "Files: 35\n",
      "Processing:  Marketing\n",
      "Files: 107\n",
      "Processing:  LawEnforcement-Security\n",
      "Files: 26\n",
      "Processing:  Publishing\n",
      "Files: 79\n",
      "Processing:  Accounting\n",
      "Files: 74\n",
      "Processing:  Education\n",
      "Files: 570\n",
      "Processing:  RealEstate\n",
      "Files: 39\n",
      "Processing:  Manufacturing\n",
      "Files: 24\n",
      "Processing:  Agriculture\n",
      "Files: 20\n",
      "Processing:  HumanResources\n",
      "Files: 53\n",
      "Processing:  Maritime\n",
      "Files: 4\n",
      "Processing:  Architecture\n",
      "Files: 35\n",
      "Processing gender: ./postprocess_blogs/blogs/male/\n",
      "Processing:  Chemicals\n",
      "Files: 39\n",
      "Processing:  Fashion\n",
      "Files: 25\n",
      "Processing:  Banking\n",
      "Files: 65\n",
      "Processing:  Construction\n",
      "Files: 33\n",
      "Processing:  Student\n",
      "Files: 2641\n",
      "Processing:  InvestmentBanking\n",
      "Files: 23\n",
      "Processing:  Engineering\n",
      "Files: 242\n",
      "Processing:  Arts\n",
      "Files: 302\n",
      "Processing:  Technology\n",
      "Files: 763\n",
      "Processing:  Consulting\n",
      "Files: 118\n",
      "Processing:  Internet\n",
      "Files: 296\n",
      "Processing:  Sports-Recreation\n",
      "Files: 54\n",
      "Processing:  Religion\n",
      "Files: 96\n",
      "Processing:  BusinessServices\n",
      "Files: 82\n",
      "Processing:  Automotive\n",
      "Files: 37\n",
      "Processing:  Tourism\n",
      "Files: 40\n",
      "Processing:  Non-Profit\n",
      "Files: 178\n",
      "Processing:  Museums-Libraries\n",
      "Files: 22\n",
      "Processing:  indUnk\n",
      "Files: 2866\n",
      "Processing:  Communications-Media\n",
      "Files: 270\n",
      "Processing:  Military\n",
      "Files: 84\n",
      "Processing:  Telecommunications\n",
      "Files: 79\n",
      "Processing:  Advertising\n",
      "Files: 70\n",
      "Processing:  Biotech\n",
      "Files: 37\n",
      "Processing:  Science\n",
      "Files: 100\n",
      "Processing:  Environment\n",
      "Files: 14\n",
      "Processing:  Government\n",
      "Files: 141\n",
      "Processing:  Law\n",
      "Files: 88\n",
      "Processing:  Transportation\n",
      "Files: 56\n",
      "Processing:  Marketing\n",
      "Files: 73\n",
      "Processing:  LawEnforcement-Security\n",
      "Files: 31\n",
      "Processing:  Publishing\n",
      "Files: 71\n",
      "Processing:  Accounting\n",
      "Files: 31\n",
      "Processing:  Education\n",
      "Files: 410\n",
      "Processing:  RealEstate\n",
      "Files: 16\n",
      "Processing:  Manufacturing\n",
      "Files: 63\n",
      "Processing:  Agriculture\n",
      "Files: 16\n",
      "Processing:  HumanResources\n",
      "Files: 41\n",
      "Processing:  Maritime\n",
      "Files: 13\n",
      "Processing:  Architecture\n",
      "Files: 34\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            name = txtDir + m + '/' + file\n",
    "            text = gettext(name)\n",
    "            words = getwords(text)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            words_s = split(words)\n",
    "            tags = [nltk.pos_tag(word) for word in words]\n",
    "            tags_s = split(tags)\n",
    "            words_l = wordlemmatize(tags_s)\n",
    "\n",
    "            F_feature = F_measure(tags_s)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            textTags = \"\"\n",
    "            for word, tag in tags_s:\n",
    "                if tag in tagList:\n",
    "                    textTags = textTags + tag + \" \"\n",
    "\n",
    "            POS_feature = []\n",
    "\n",
    "            for feature in posFeatures:\n",
    "                if feature in textTags:\n",
    "                    POS_feature.append(1)\n",
    "                else:\n",
    "                    POS_feature.append(0)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            POS_features.append(POS_feature)\n",
    "            labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsingle(features, n):\n",
    "    single = []\n",
    "    for item in features:\n",
    "        single.append(item[n])\n",
    "    return single\n",
    "\n",
    "\n",
    "WC_features_l = []\n",
    "for i in range(23):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "GRF_features_l = []\n",
    "for i in range(10):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "POS_features_l = []\n",
    "for i in range(33):\n",
    "    n = i\n",
    "    POS_features_l.append(getsingle(POS_features, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(23):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(10):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(33):\n",
    "    key = 'POS_' + str(i + 1)\n",
    "    value = POS_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allofall.to_csv('allofall.csv',index = False)\n",
    "allofall = pd.read_csv('allofall.csv')\n",
    "df_per_txt = pd.read_csv('blogs_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>label</th>\n",
       "      <th>F_feature</th>\n",
       "      <th>WC_1</th>\n",
       "      <th>WC_2</th>\n",
       "      <th>WC_3</th>\n",
       "      <th>WC_4</th>\n",
       "      <th>WC_5</th>\n",
       "      <th>WC_6</th>\n",
       "      <th>WC_7</th>\n",
       "      <th>...</th>\n",
       "      <th>POS_26</th>\n",
       "      <th>POS_27</th>\n",
       "      <th>POS_28</th>\n",
       "      <th>POS_29</th>\n",
       "      <th>POS_30</th>\n",
       "      <th>POS_31</th>\n",
       "      <th>POS_32</th>\n",
       "      <th>POS_33</th>\n",
       "      <th>word ratio</th>\n",
       "      <th>bias</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/344...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.169566</td>\n",
       "      <td>0.107692</td>\n",
       "      <td>0.112821</td>\n",
       "      <td>0.042735</td>\n",
       "      <td>0.104274</td>\n",
       "      <td>0.061538</td>\n",
       "      <td>0.010256</td>\n",
       "      <td>0.034188</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.289545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/407...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.293140</td>\n",
       "      <td>0.149425</td>\n",
       "      <td>0.022989</td>\n",
       "      <td>0.080460</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011494</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/340...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.948334</td>\n",
       "      <td>0.112903</td>\n",
       "      <td>0.085253</td>\n",
       "      <td>0.086790</td>\n",
       "      <td>0.035330</td>\n",
       "      <td>0.052227</td>\n",
       "      <td>0.009985</td>\n",
       "      <td>0.035330</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.502463e-01</td>\n",
       "      <td>0.940899</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/339...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.295692</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.115000</td>\n",
       "      <td>0.075000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.035000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.347826e-01</td>\n",
       "      <td>0.810930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/398...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.282569</td>\n",
       "      <td>0.158273</td>\n",
       "      <td>0.100719</td>\n",
       "      <td>0.028777</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.043165</td>\n",
       "      <td>0.014388</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.133531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/364...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.948802</td>\n",
       "      <td>0.134003</td>\n",
       "      <td>0.038848</td>\n",
       "      <td>0.067220</td>\n",
       "      <td>0.034046</td>\n",
       "      <td>0.046704</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.074640</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.824561e-01</td>\n",
       "      <td>0.541787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/409...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.241013</td>\n",
       "      <td>0.157480</td>\n",
       "      <td>0.051181</td>\n",
       "      <td>0.043307</td>\n",
       "      <td>0.094488</td>\n",
       "      <td>0.055118</td>\n",
       "      <td>0.019685</td>\n",
       "      <td>0.039370</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.419355e-01</td>\n",
       "      <td>1.165503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/716...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.285121</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.176471</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.117647</td>\n",
       "      <td>0.023529</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.500001e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/405...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.265072</td>\n",
       "      <td>0.139738</td>\n",
       "      <td>0.122271</td>\n",
       "      <td>0.013100</td>\n",
       "      <td>0.052402</td>\n",
       "      <td>0.030568</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034934</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.000000e-01</td>\n",
       "      <td>0.810930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/380...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.253772</td>\n",
       "      <td>0.114379</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.068627</td>\n",
       "      <td>0.173203</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.009804</td>\n",
       "      <td>0.032680</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.500000e-01</td>\n",
       "      <td>0.154151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/417...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.285121</td>\n",
       "      <td>0.092593</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>0.018519</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000001e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/409...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.305899</td>\n",
       "      <td>0.126761</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.084507</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.042254</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.999998e-07</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/406...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.286579</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.153061</td>\n",
       "      <td>0.040816</td>\n",
       "      <td>0.122449</td>\n",
       "      <td>0.102041</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.061224</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666668e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/166...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524857</td>\n",
       "      <td>0.189512</td>\n",
       "      <td>0.036345</td>\n",
       "      <td>0.035826</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>0.043614</td>\n",
       "      <td>0.015576</td>\n",
       "      <td>0.032191</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.048711e-01</td>\n",
       "      <td>0.815642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/367...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.100306</td>\n",
       "      <td>0.203158</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.037895</td>\n",
       "      <td>0.054737</td>\n",
       "      <td>0.082105</td>\n",
       "      <td>0.007368</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.758065e-01</td>\n",
       "      <td>0.476777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/351...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.100306</td>\n",
       "      <td>0.189744</td>\n",
       "      <td>0.068132</td>\n",
       "      <td>0.039560</td>\n",
       "      <td>0.027106</td>\n",
       "      <td>0.034432</td>\n",
       "      <td>0.008059</td>\n",
       "      <td>0.024176</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.177419e-01</td>\n",
       "      <td>0.929878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/348...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.096661</td>\n",
       "      <td>0.143021</td>\n",
       "      <td>0.030892</td>\n",
       "      <td>0.059497</td>\n",
       "      <td>0.016018</td>\n",
       "      <td>0.044622</td>\n",
       "      <td>0.001144</td>\n",
       "      <td>0.042334</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.069767e-01</td>\n",
       "      <td>2.205003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/288...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.097390</td>\n",
       "      <td>0.135899</td>\n",
       "      <td>0.092002</td>\n",
       "      <td>0.036681</td>\n",
       "      <td>0.042093</td>\n",
       "      <td>0.058328</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.046302</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.051661e-01</td>\n",
       "      <td>0.710878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/183...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.168350</td>\n",
       "      <td>0.143541</td>\n",
       "      <td>0.087150</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>0.041353</td>\n",
       "      <td>0.039986</td>\n",
       "      <td>0.006152</td>\n",
       "      <td>0.036227</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "      <td>0.708804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/408...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.286214</td>\n",
       "      <td>0.149254</td>\n",
       "      <td>0.069652</td>\n",
       "      <td>0.019900</td>\n",
       "      <td>0.104478</td>\n",
       "      <td>0.079602</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.034826</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/419...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.295692</td>\n",
       "      <td>0.152778</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.069444</td>\n",
       "      <td>0.013889</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.857143e-01</td>\n",
       "      <td>1.466337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/419...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.293870</td>\n",
       "      <td>0.135135</td>\n",
       "      <td>0.054054</td>\n",
       "      <td>0.027027</td>\n",
       "      <td>0.033784</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.013514</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.500000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Chemicals/350...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.307722</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.017241</td>\n",
       "      <td>0.086207</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.600000e-01</td>\n",
       "      <td>2.524928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/41018...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.274185</td>\n",
       "      <td>0.149020</td>\n",
       "      <td>0.098039</td>\n",
       "      <td>0.050980</td>\n",
       "      <td>0.109804</td>\n",
       "      <td>0.094118</td>\n",
       "      <td>0.015686</td>\n",
       "      <td>0.011765</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.590909e-01</td>\n",
       "      <td>1.284394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/42633...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.289860</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.092105</td>\n",
       "      <td>0.118421</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.026316</td>\n",
       "      <td>0.013158</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/41439...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.150611</td>\n",
       "      <td>0.167131</td>\n",
       "      <td>0.044568</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>0.011142</td>\n",
       "      <td>0.041783</td>\n",
       "      <td>0.013928</td>\n",
       "      <td>0.025070</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.774194e-01</td>\n",
       "      <td>0.640467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/41280...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.322303</td>\n",
       "      <td>0.234848</td>\n",
       "      <td>0.121212</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.075758</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.260870e-01</td>\n",
       "      <td>1.734601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/41273...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.294599</td>\n",
       "      <td>0.165236</td>\n",
       "      <td>0.094421</td>\n",
       "      <td>0.072961</td>\n",
       "      <td>0.019313</td>\n",
       "      <td>0.027897</td>\n",
       "      <td>0.010730</td>\n",
       "      <td>0.103004</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.320000e-01</td>\n",
       "      <td>0.519416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/41840...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.257052</td>\n",
       "      <td>0.123404</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.042553</td>\n",
       "      <td>0.004255</td>\n",
       "      <td>0.063830</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.038298</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.636364e-01</td>\n",
       "      <td>0.439846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>./postprocess_blogs/blogs/female/Fashion/39369...</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.229348</td>\n",
       "      <td>0.191740</td>\n",
       "      <td>0.082596</td>\n",
       "      <td>0.029499</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.050147</td>\n",
       "      <td>0.005900</td>\n",
       "      <td>0.023599</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.846154e-01</td>\n",
       "      <td>1.612434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/36...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.041253</td>\n",
       "      <td>0.083485</td>\n",
       "      <td>0.041742</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.032668</td>\n",
       "      <td>0.063521</td>\n",
       "      <td>0.005445</td>\n",
       "      <td>0.219601</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.303030e-01</td>\n",
       "      <td>0.366353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19291</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/42...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.290589</td>\n",
       "      <td>0.295775</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.183099</td>\n",
       "      <td>0.028169</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.014085</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000001e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/35...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.225703</td>\n",
       "      <td>0.152866</td>\n",
       "      <td>0.101911</td>\n",
       "      <td>0.019108</td>\n",
       "      <td>0.031847</td>\n",
       "      <td>0.050955</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.127389</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>0.428725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19293</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/34...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.040524</td>\n",
       "      <td>0.167513</td>\n",
       "      <td>0.020305</td>\n",
       "      <td>0.025381</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.045685</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.708050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19294</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/34...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.054740</td>\n",
       "      <td>0.111765</td>\n",
       "      <td>0.088235</td>\n",
       "      <td>0.045098</td>\n",
       "      <td>0.090196</td>\n",
       "      <td>0.113725</td>\n",
       "      <td>0.013725</td>\n",
       "      <td>0.060784</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.543478e-01</td>\n",
       "      <td>0.751326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19295</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/35...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.118775</td>\n",
       "      <td>0.099196</td>\n",
       "      <td>0.067024</td>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.044236</td>\n",
       "      <td>0.032172</td>\n",
       "      <td>0.010724</td>\n",
       "      <td>0.057641</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.352941e-01</td>\n",
       "      <td>1.457325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19296</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/41...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.287308</td>\n",
       "      <td>0.217391</td>\n",
       "      <td>0.173913</td>\n",
       "      <td>0.054348</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.021739</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.750000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/39...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.273092</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3.076924e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/33...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.167743</td>\n",
       "      <td>0.196429</td>\n",
       "      <td>0.057540</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.005952</td>\n",
       "      <td>0.033730</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.129032e-01</td>\n",
       "      <td>0.346574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/34...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.261427</td>\n",
       "      <td>0.057971</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>0.188406</td>\n",
       "      <td>0.231884</td>\n",
       "      <td>0.072464</td>\n",
       "      <td>0.014493</td>\n",
       "      <td>0.028986</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.000000e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/37...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.156078</td>\n",
       "      <td>0.202516</td>\n",
       "      <td>0.113208</td>\n",
       "      <td>0.018868</td>\n",
       "      <td>0.040252</td>\n",
       "      <td>0.055346</td>\n",
       "      <td>0.026415</td>\n",
       "      <td>0.044025</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.082111e-01</td>\n",
       "      <td>1.384942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/33...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.202738</td>\n",
       "      <td>0.137255</td>\n",
       "      <td>0.049774</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>0.040724</td>\n",
       "      <td>0.064857</td>\n",
       "      <td>0.013575</td>\n",
       "      <td>0.037707</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.646465e-01</td>\n",
       "      <td>0.443866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/58...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.458513</td>\n",
       "      <td>0.171635</td>\n",
       "      <td>0.048558</td>\n",
       "      <td>0.045192</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.058173</td>\n",
       "      <td>0.008173</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.021352e-01</td>\n",
       "      <td>0.551730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/40...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.278195</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.055556</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.077778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022222</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.666667e-01</td>\n",
       "      <td>1.178655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/39...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.201644</td>\n",
       "      <td>0.052830</td>\n",
       "      <td>0.067925</td>\n",
       "      <td>0.041509</td>\n",
       "      <td>0.060377</td>\n",
       "      <td>0.022642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.056604</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>5.714286e-01</td>\n",
       "      <td>0.287682</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/33...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.274550</td>\n",
       "      <td>0.032609</td>\n",
       "      <td>0.163043</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>0.119565</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.010870</td>\n",
       "      <td>0.086957</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000002e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/34...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.264343</td>\n",
       "      <td>0.238938</td>\n",
       "      <td>0.035398</td>\n",
       "      <td>0.048673</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022124</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.026549</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.888889e-01</td>\n",
       "      <td>2.639057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/40...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.052553</td>\n",
       "      <td>0.128105</td>\n",
       "      <td>0.104575</td>\n",
       "      <td>0.035294</td>\n",
       "      <td>0.049673</td>\n",
       "      <td>0.060131</td>\n",
       "      <td>0.014379</td>\n",
       "      <td>0.061438</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.047619e-01</td>\n",
       "      <td>1.848927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/41...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266530</td>\n",
       "      <td>0.075377</td>\n",
       "      <td>0.035176</td>\n",
       "      <td>0.030151</td>\n",
       "      <td>0.020101</td>\n",
       "      <td>0.060302</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.206030</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8.666667e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/30...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.191438</td>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.051948</td>\n",
       "      <td>0.112554</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.025974</td>\n",
       "      <td>0.008658</td>\n",
       "      <td>0.112554</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "      <td>0.981111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/16...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.273334</td>\n",
       "      <td>0.135770</td>\n",
       "      <td>0.079634</td>\n",
       "      <td>0.057441</td>\n",
       "      <td>0.044386</td>\n",
       "      <td>0.073107</td>\n",
       "      <td>0.005222</td>\n",
       "      <td>0.084856</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.605634e-01</td>\n",
       "      <td>0.662537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/34...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.131291</td>\n",
       "      <td>0.116564</td>\n",
       "      <td>0.027607</td>\n",
       "      <td>0.073620</td>\n",
       "      <td>0.012270</td>\n",
       "      <td>0.055215</td>\n",
       "      <td>0.003067</td>\n",
       "      <td>0.082822</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.512195e-01</td>\n",
       "      <td>2.322195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/35...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065554</td>\n",
       "      <td>0.118830</td>\n",
       "      <td>0.053016</td>\n",
       "      <td>0.023766</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.074954</td>\n",
       "      <td>0.009141</td>\n",
       "      <td>0.060329</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>9.166667e-01</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/32...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.266530</td>\n",
       "      <td>0.151934</td>\n",
       "      <td>0.085635</td>\n",
       "      <td>0.058011</td>\n",
       "      <td>0.024862</td>\n",
       "      <td>0.088398</td>\n",
       "      <td>0.008287</td>\n",
       "      <td>0.049724</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.411765e-01</td>\n",
       "      <td>0.387717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/35...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.183053</td>\n",
       "      <td>0.133911</td>\n",
       "      <td>0.071291</td>\n",
       "      <td>0.075145</td>\n",
       "      <td>0.028902</td>\n",
       "      <td>0.053950</td>\n",
       "      <td>0.017341</td>\n",
       "      <td>0.057803</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.824176e-01</td>\n",
       "      <td>1.170369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/27...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.437371</td>\n",
       "      <td>0.085120</td>\n",
       "      <td>0.038337</td>\n",
       "      <td>0.035088</td>\n",
       "      <td>0.068876</td>\n",
       "      <td>0.087719</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.120858</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.750000e-01</td>\n",
       "      <td>1.189811</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/35...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.209664</td>\n",
       "      <td>0.227273</td>\n",
       "      <td>0.090909</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.036364</td>\n",
       "      <td>0.009091</td>\n",
       "      <td>0.063636</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.187500e-01</td>\n",
       "      <td>0.207639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/37...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.021568</td>\n",
       "      <td>0.093489</td>\n",
       "      <td>0.073456</td>\n",
       "      <td>0.081803</td>\n",
       "      <td>0.071786</td>\n",
       "      <td>0.061770</td>\n",
       "      <td>0.013356</td>\n",
       "      <td>0.051753</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.183206e-01</td>\n",
       "      <td>0.524332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/32...</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.292047</td>\n",
       "      <td>0.105000</td>\n",
       "      <td>0.045000</td>\n",
       "      <td>0.150000</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.065000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.085000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6.388889e-01</td>\n",
       "      <td>0.693050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>./postprocess_blogs/blogs/male/Architecture/36...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.074667</td>\n",
       "      <td>0.145320</td>\n",
       "      <td>0.064039</td>\n",
       "      <td>0.029557</td>\n",
       "      <td>0.034483</td>\n",
       "      <td>0.022167</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.044335</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>8.333333e-01</td>\n",
       "      <td>2.564949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    name  label  F_feature  \\\n",
       "0      ./postprocess_blogs/blogs/female/Chemicals/344...      0  -0.169566   \n",
       "1      ./postprocess_blogs/blogs/female/Chemicals/407...      0  -0.293140   \n",
       "2      ./postprocess_blogs/blogs/female/Chemicals/340...      0   1.948334   \n",
       "3      ./postprocess_blogs/blogs/female/Chemicals/339...      0  -0.295692   \n",
       "4      ./postprocess_blogs/blogs/female/Chemicals/398...      0  -0.282569   \n",
       "5      ./postprocess_blogs/blogs/female/Chemicals/364...      0   0.948802   \n",
       "6      ./postprocess_blogs/blogs/female/Chemicals/409...      0  -0.241013   \n",
       "7      ./postprocess_blogs/blogs/female/Chemicals/716...      0  -0.285121   \n",
       "8      ./postprocess_blogs/blogs/female/Chemicals/405...      0  -0.265072   \n",
       "9      ./postprocess_blogs/blogs/female/Chemicals/380...      0  -0.253772   \n",
       "10     ./postprocess_blogs/blogs/female/Chemicals/417...      0  -0.285121   \n",
       "11     ./postprocess_blogs/blogs/female/Chemicals/409...      0  -0.305899   \n",
       "12     ./postprocess_blogs/blogs/female/Chemicals/406...      0  -0.286579   \n",
       "13     ./postprocess_blogs/blogs/female/Chemicals/166...      0   0.524857   \n",
       "14     ./postprocess_blogs/blogs/female/Chemicals/367...      0  -0.100306   \n",
       "15     ./postprocess_blogs/blogs/female/Chemicals/351...      0  -0.100306   \n",
       "16     ./postprocess_blogs/blogs/female/Chemicals/348...      0  -0.096661   \n",
       "17     ./postprocess_blogs/blogs/female/Chemicals/288...      0  -0.097390   \n",
       "18     ./postprocess_blogs/blogs/female/Chemicals/183...      0   0.168350   \n",
       "19     ./postprocess_blogs/blogs/female/Chemicals/408...      0  -0.286214   \n",
       "20     ./postprocess_blogs/blogs/female/Chemicals/419...      0  -0.295692   \n",
       "21     ./postprocess_blogs/blogs/female/Chemicals/419...      0  -0.293870   \n",
       "22     ./postprocess_blogs/blogs/female/Chemicals/350...      0  -0.307722   \n",
       "23     ./postprocess_blogs/blogs/female/Fashion/41018...      0  -0.274185   \n",
       "24     ./postprocess_blogs/blogs/female/Fashion/42633...      0  -0.289860   \n",
       "25     ./postprocess_blogs/blogs/female/Fashion/41439...      0  -0.150611   \n",
       "26     ./postprocess_blogs/blogs/female/Fashion/41280...      0  -0.322303   \n",
       "27     ./postprocess_blogs/blogs/female/Fashion/41273...      0  -0.294599   \n",
       "28     ./postprocess_blogs/blogs/female/Fashion/41840...      0  -0.257052   \n",
       "29     ./postprocess_blogs/blogs/female/Fashion/39369...      0  -0.229348   \n",
       "...                                                  ...    ...        ...   \n",
       "19290  ./postprocess_blogs/blogs/male/Architecture/36...      1  -0.041253   \n",
       "19291  ./postprocess_blogs/blogs/male/Architecture/42...      1  -0.290589   \n",
       "19292  ./postprocess_blogs/blogs/male/Architecture/35...      1  -0.225703   \n",
       "19293  ./postprocess_blogs/blogs/male/Architecture/34...      1  -0.040524   \n",
       "19294  ./postprocess_blogs/blogs/male/Architecture/34...      1  -0.054740   \n",
       "19295  ./postprocess_blogs/blogs/male/Architecture/35...      1   0.118775   \n",
       "19296  ./postprocess_blogs/blogs/male/Architecture/41...      1  -0.287308   \n",
       "19297  ./postprocess_blogs/blogs/male/Architecture/39...      1  -0.273092   \n",
       "19298  ./postprocess_blogs/blogs/male/Architecture/33...      1  -0.167743   \n",
       "19299  ./postprocess_blogs/blogs/male/Architecture/34...      1  -0.261427   \n",
       "19300  ./postprocess_blogs/blogs/male/Architecture/37...      1  -0.156078   \n",
       "19301  ./postprocess_blogs/blogs/male/Architecture/33...      1  -0.202738   \n",
       "19302  ./postprocess_blogs/blogs/male/Architecture/58...      1   0.458513   \n",
       "19303  ./postprocess_blogs/blogs/male/Architecture/40...      1  -0.278195   \n",
       "19304  ./postprocess_blogs/blogs/male/Architecture/39...      1  -0.201644   \n",
       "19305  ./postprocess_blogs/blogs/male/Architecture/33...      1  -0.274550   \n",
       "19306  ./postprocess_blogs/blogs/male/Architecture/34...      1  -0.264343   \n",
       "19307  ./postprocess_blogs/blogs/male/Architecture/40...      1  -0.052553   \n",
       "19308  ./postprocess_blogs/blogs/male/Architecture/41...      1  -0.266530   \n",
       "19309  ./postprocess_blogs/blogs/male/Architecture/30...      1  -0.191438   \n",
       "19310  ./postprocess_blogs/blogs/male/Architecture/16...      1   0.273334   \n",
       "19311  ./postprocess_blogs/blogs/male/Architecture/34...      1  -0.131291   \n",
       "19312  ./postprocess_blogs/blogs/male/Architecture/35...      1   0.065554   \n",
       "19313  ./postprocess_blogs/blogs/male/Architecture/32...      1  -0.266530   \n",
       "19314  ./postprocess_blogs/blogs/male/Architecture/35...      1  -0.183053   \n",
       "19315  ./postprocess_blogs/blogs/male/Architecture/27...      1   0.437371   \n",
       "19316  ./postprocess_blogs/blogs/male/Architecture/35...      1  -0.209664   \n",
       "19317  ./postprocess_blogs/blogs/male/Architecture/37...      1  -0.021568   \n",
       "19318  ./postprocess_blogs/blogs/male/Architecture/32...      1  -0.292047   \n",
       "19319  ./postprocess_blogs/blogs/male/Architecture/36...      1   0.074667   \n",
       "\n",
       "           WC_1      WC_2      WC_3      WC_4      WC_5      WC_6      WC_7  \\\n",
       "0      0.107692  0.112821  0.042735  0.104274  0.061538  0.010256  0.034188   \n",
       "1      0.149425  0.022989  0.080460  0.011494  0.034483  0.000000  0.011494   \n",
       "2      0.112903  0.085253  0.086790  0.035330  0.052227  0.009985  0.035330   \n",
       "3      0.105000  0.115000  0.075000  0.065000  0.035000  0.015000  0.055000   \n",
       "4      0.158273  0.100719  0.028777  0.043165  0.043165  0.014388  0.000000   \n",
       "5      0.134003  0.038848  0.067220  0.034046  0.046704  0.004801  0.074640   \n",
       "6      0.157480  0.051181  0.043307  0.094488  0.055118  0.019685  0.039370   \n",
       "7      0.117647  0.176471  0.035294  0.117647  0.023529  0.000000  0.035294   \n",
       "8      0.139738  0.122271  0.013100  0.052402  0.030568  0.000000  0.034934   \n",
       "9      0.114379  0.104575  0.068627  0.173203  0.055556  0.009804  0.032680   \n",
       "10     0.092593  0.111111  0.074074  0.018519  0.000000  0.000000  0.222222   \n",
       "11     0.126761  0.028169  0.042254  0.014085  0.084507  0.000000  0.042254   \n",
       "12     0.102041  0.153061  0.040816  0.122449  0.102041  0.000000  0.061224   \n",
       "13     0.189512  0.036345  0.035826  0.024403  0.043614  0.015576  0.032191   \n",
       "14     0.203158  0.060000  0.037895  0.054737  0.082105  0.007368  0.040000   \n",
       "15     0.189744  0.068132  0.039560  0.027106  0.034432  0.008059  0.024176   \n",
       "16     0.143021  0.030892  0.059497  0.016018  0.044622  0.001144  0.042334   \n",
       "17     0.135899  0.092002  0.036681  0.042093  0.058328  0.007216  0.046302   \n",
       "18     0.143541  0.087150  0.039986  0.041353  0.039986  0.006152  0.036227   \n",
       "19     0.149254  0.069652  0.019900  0.104478  0.079602  0.000000  0.034826   \n",
       "20     0.152778  0.055556  0.069444  0.013889  0.083333  0.000000  0.000000   \n",
       "21     0.135135  0.054054  0.027027  0.033784  0.060811  0.000000  0.013514   \n",
       "22     0.068966  0.068966  0.068966  0.017241  0.086207  0.034483  0.051724   \n",
       "23     0.149020  0.098039  0.050980  0.109804  0.094118  0.015686  0.011765   \n",
       "24     0.065789  0.092105  0.118421  0.131579  0.026316  0.013158  0.052632   \n",
       "25     0.167131  0.044568  0.025070  0.011142  0.041783  0.013928  0.025070   \n",
       "26     0.234848  0.121212  0.060606  0.090909  0.075758  0.000000  0.030303   \n",
       "27     0.165236  0.094421  0.072961  0.019313  0.027897  0.010730  0.103004   \n",
       "28     0.123404  0.042553  0.042553  0.004255  0.063830  0.000000  0.038298   \n",
       "29     0.191740  0.082596  0.029499  0.020649  0.050147  0.005900  0.023599   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "19290  0.083485  0.041742  0.068966  0.032668  0.063521  0.005445  0.219601   \n",
       "19291  0.295775  0.056338  0.183099  0.028169  0.056338  0.014085  0.056338   \n",
       "19292  0.152866  0.101911  0.019108  0.031847  0.050955  0.006369  0.127389   \n",
       "19293  0.167513  0.020305  0.025381  0.000000  0.045685  0.000000  0.015228   \n",
       "19294  0.111765  0.088235  0.045098  0.090196  0.113725  0.013725  0.060784   \n",
       "19295  0.099196  0.067024  0.053619  0.044236  0.032172  0.010724  0.057641   \n",
       "19296  0.217391  0.173913  0.054348  0.032609  0.021739  0.010870  0.032609   \n",
       "19297  0.150000  0.083333  0.100000  0.033333  0.083333  0.016667  0.033333   \n",
       "19298  0.196429  0.057540  0.053571  0.033730  0.041667  0.005952  0.033730   \n",
       "19299  0.057971  0.028986  0.188406  0.231884  0.072464  0.014493  0.028986   \n",
       "19300  0.202516  0.113208  0.018868  0.040252  0.055346  0.026415  0.044025   \n",
       "19301  0.137255  0.049774  0.087481  0.040724  0.064857  0.013575  0.037707   \n",
       "19302  0.171635  0.048558  0.045192  0.057692  0.058173  0.008173  0.038462   \n",
       "19303  0.100000  0.055556  0.188889  0.000000  0.077778  0.000000  0.022222   \n",
       "19304  0.052830  0.067925  0.041509  0.060377  0.022642  0.000000  0.056604   \n",
       "19305  0.032609  0.163043  0.043478  0.119565  0.065217  0.010870  0.086957   \n",
       "19306  0.238938  0.035398  0.048673  0.000000  0.022124  0.000000  0.026549   \n",
       "19307  0.128105  0.104575  0.035294  0.049673  0.060131  0.014379  0.061438   \n",
       "19308  0.075377  0.035176  0.030151  0.020101  0.060302  0.010050  0.206030   \n",
       "19309  0.095238  0.051948  0.112554  0.047619  0.025974  0.008658  0.112554   \n",
       "19310  0.135770  0.079634  0.057441  0.044386  0.073107  0.005222  0.084856   \n",
       "19311  0.116564  0.027607  0.073620  0.012270  0.055215  0.003067  0.082822   \n",
       "19312  0.118830  0.053016  0.023766  0.034735  0.074954  0.009141  0.060329   \n",
       "19313  0.151934  0.085635  0.058011  0.024862  0.088398  0.008287  0.049724   \n",
       "19314  0.133911  0.071291  0.075145  0.028902  0.053950  0.017341  0.057803   \n",
       "19315  0.085120  0.038337  0.035088  0.068876  0.087719  0.002599  0.120858   \n",
       "19316  0.227273  0.090909  0.036364  0.036364  0.036364  0.009091  0.063636   \n",
       "19317  0.093489  0.073456  0.081803  0.071786  0.061770  0.013356  0.051753   \n",
       "19318  0.105000  0.045000  0.150000  0.030000  0.065000  0.010000  0.085000   \n",
       "19319  0.145320  0.064039  0.029557  0.034483  0.022167  0.000000  0.044335   \n",
       "\n",
       "       ...  POS_26  POS_27  POS_28  POS_29  POS_30  POS_31  POS_32  POS_33  \\\n",
       "0      ...       1       1       0       1       1       0       1       0   \n",
       "1      ...       1       0       0       1       1       0       1       0   \n",
       "2      ...       1       1       1       1       1       1       1       0   \n",
       "3      ...       1       0       0       1       1       0       1       0   \n",
       "4      ...       1       1       0       1       1       0       1       0   \n",
       "5      ...       1       1       1       1       1       1       1       0   \n",
       "6      ...       1       1       0       1       1       1       1       0   \n",
       "7      ...       1       0       1       1       1       0       1       0   \n",
       "8      ...       1       0       1       1       1       0       1       0   \n",
       "9      ...       1       1       1       1       1       1       1       0   \n",
       "10     ...       1       1       0       1       1       0       1       0   \n",
       "11     ...       1       0       0       1       1       0       1       0   \n",
       "12     ...       1       1       1       1       1       0       1       0   \n",
       "13     ...       1       1       1       1       1       1       1       0   \n",
       "14     ...       1       1       1       1       1       1       1       0   \n",
       "15     ...       1       1       0       1       1       1       1       0   \n",
       "16     ...       1       1       1       1       1       1       1       0   \n",
       "17     ...       1       1       1       1       1       1       1       0   \n",
       "18     ...       1       1       1       1       1       1       1       0   \n",
       "19     ...       1       1       1       1       1       0       1       0   \n",
       "20     ...       1       0       0       1       1       1       1       0   \n",
       "21     ...       1       1       0       1       1       1       1       0   \n",
       "22     ...       1       1       0       1       1       0       1       0   \n",
       "23     ...       1       1       0       1       1       0       1       0   \n",
       "24     ...       1       1       0       1       1       0       1       0   \n",
       "25     ...       1       1       1       1       1       0       1       0   \n",
       "26     ...       1       1       0       1       1       0       1       0   \n",
       "27     ...       1       1       1       1       1       1       1       0   \n",
       "28     ...       1       1       1       1       1       0       1       0   \n",
       "29     ...       1       1       0       1       1       0       1       0   \n",
       "...    ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "19290  ...       1       1       1       1       1       1       1       0   \n",
       "19291  ...       1       1       0       1       1       0       1       0   \n",
       "19292  ...       1       1       0       1       1       0       1       0   \n",
       "19293  ...       1       1       1       1       1       0       1       0   \n",
       "19294  ...       1       1       0       1       1       0       1       0   \n",
       "19295  ...       1       1       1       1       1       1       1       0   \n",
       "19296  ...       1       0       1       1       1       0       1       0   \n",
       "19297  ...       1       1       0       1       1       0       1       0   \n",
       "19298  ...       1       1       1       1       1       1       1       0   \n",
       "19299  ...       1       0       0       1       0       0       1       0   \n",
       "19300  ...       1       1       1       1       1       1       1       0   \n",
       "19301  ...       1       1       1       1       1       1       1       0   \n",
       "19302  ...       1       1       1       1       1       1       1       0   \n",
       "19303  ...       1       1       0       1       1       0       1       0   \n",
       "19304  ...       1       1       1       1       1       0       1       0   \n",
       "19305  ...       1       1       0       1       1       0       1       0   \n",
       "19306  ...       1       1       1       1       1       0       1       0   \n",
       "19307  ...       1       1       1       1       1       1       1       0   \n",
       "19308  ...       1       1       0       1       1       0       1       0   \n",
       "19309  ...       1       1       1       1       1       0       1       0   \n",
       "19310  ...       1       1       0       1       1       0       1       0   \n",
       "19311  ...       1       1       1       1       1       1       1       0   \n",
       "19312  ...       1       1       1       1       1       0       1       0   \n",
       "19313  ...       1       1       0       1       1       1       1       0   \n",
       "19314  ...       1       1       1       1       1       1       1       0   \n",
       "19315  ...       1       1       1       1       1       0       1       0   \n",
       "19316  ...       1       1       0       1       1       0       1       0   \n",
       "19317  ...       1       1       1       1       1       1       1       0   \n",
       "19318  ...       1       0       0       1       1       0       1       0   \n",
       "19319  ...       1       1       1       1       1       1       1       1   \n",
       "\n",
       "         word ratio      bias  \n",
       "0      5.000000e-01  0.289545  \n",
       "1      1.000000e+00  0.000000  \n",
       "2      6.502463e-01  0.940899  \n",
       "3      4.347826e-01  0.810930  \n",
       "4      5.000000e-01  0.133531  \n",
       "5      5.824561e-01  0.541787  \n",
       "6      7.419355e-01  1.165503  \n",
       "7      7.500001e-01  0.000000  \n",
       "8      6.000000e-01  0.810930  \n",
       "9      5.500000e-01  0.154151  \n",
       "10     4.000001e-01  0.000000  \n",
       "11     4.999998e-07  0.000000  \n",
       "12     6.666668e-01  0.000000  \n",
       "13     7.048711e-01  0.815642  \n",
       "14     4.758065e-01  0.476777  \n",
       "15     7.177419e-01  0.929878  \n",
       "16     9.069767e-01  2.205003  \n",
       "17     6.051661e-01  0.710878  \n",
       "18     6.530612e-01  0.708804  \n",
       "19     5.000000e-01  0.000000  \n",
       "20     2.857143e-01  1.466337  \n",
       "21     9.500000e-01  0.000000  \n",
       "22     9.600000e-01  2.524928  \n",
       "23     6.590909e-01  1.284394  \n",
       "24     5.000000e-01  0.000000  \n",
       "25     6.774194e-01  0.640467  \n",
       "26     8.260870e-01  1.734601  \n",
       "27     4.320000e-01  0.519416  \n",
       "28     3.636364e-01  0.439846  \n",
       "29     8.846154e-01  1.612434  \n",
       "...             ...       ...  \n",
       "19290  5.303030e-01  0.366353  \n",
       "19291  5.000001e-01  0.000000  \n",
       "19292  5.000000e-01  0.428725  \n",
       "19293  1.000000e+00  2.708050  \n",
       "19294  5.543478e-01  0.751326  \n",
       "19295  7.352941e-01  1.457325  \n",
       "19296  8.750000e-01  0.000000  \n",
       "19297  3.076924e-01  0.000000  \n",
       "19298  6.129032e-01  0.346574  \n",
       "19299  7.000000e-01  0.000000  \n",
       "19300  2.082111e-01  1.384942  \n",
       "19301  4.646465e-01  0.443866  \n",
       "19302  4.021352e-01  0.551730  \n",
       "19303  6.666667e-01  1.178655  \n",
       "19304  5.714286e-01  0.287682  \n",
       "19305  2.000002e-01  0.000000  \n",
       "19306  8.888889e-01  2.639057  \n",
       "19307  9.047619e-01  1.848927  \n",
       "19308  8.666667e-01  0.000000  \n",
       "19309  6.530612e-01  0.981111  \n",
       "19310  7.605634e-01  0.662537  \n",
       "19311  9.512195e-01  2.322195  \n",
       "19312  9.166667e-01  0.000000  \n",
       "19313  4.411765e-01  0.387717  \n",
       "19314  7.824176e-01  1.170369  \n",
       "19315  7.750000e-01  1.189811  \n",
       "19316  7.187500e-01  0.207639  \n",
       "19317  6.183206e-01  0.524332  \n",
       "19318  6.388889e-01  0.693050  \n",
       "19319  8.333333e-01  2.564949  \n",
       "\n",
       "[19320 rows x 71 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allofall['word ratio'], allofall['bias'] = df_per_txt['word ratio'], df_per_txt['bias']\n",
    "allofall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data, target = allofall.drop(\n",
    "    columns=['name', 'label']).iloc[:].values, allofall['label'].values\n",
    "train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                    target,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=42,\n",
    "                                                    shuffle=True)\n",
    "data, target = pd.concat(\n",
    "    (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "        (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "data1 = data.iloc[:, :63]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7025 0.705  0.7225 0.755  0.7525]\n",
      "Accuracy: 0.73 (+/- 0.05)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                 max_leaf_nodes=50,\n",
    "                                 n_jobs=-1)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target1.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.685 0.735 0.72  0.735 0.7  ]\n",
      "Accuracy: 0.71 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = SVC(kernel='rbf', gamma=0.1, probability=True, C=1000)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data1.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.69   0.715  0.7025 0.755  0.7125]\n",
      "Accuracy: 0.71 (+/- 0.04)\n"
     ]
    }
   ],
   "source": [
    "rnd_clf = sklearn.tree.DecisionTreeClassifier(max_leaf_nodes=50)\n",
    "scores_rnd_clf_cv = cross_val_score(rnd_clf,data.values,target.values.reshape(-1,),cv=5)\n",
    "print(scores_rnd_clf_cv)\n",
    "print(\"Accuracy: %0.2f (+/- %0.2f)\" % (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'svr_clf = SVR(kernel=\\'rbf\\', gamma=2.0, C=10)\\nsvr_clf.fit(train_X, train_y)\\n\\nsvc_clf = SVC(kernel=\\'rbf\\', gamma=2.0, probability=True, C=10)\\nsvc_clf.fit(train_X, train_y)\\n\\nsvc_poly_clf = SVC(kernel=\"poly\", probability=True, degree=3, coef0=1, C=5)\\nsvc_poly_clf.fit(train_X, train_y)\\n\\nlog_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\\nlog_clf.fit(train_X, train_y)\\n\\nvoting_clf = VotingClassifier(estimators=[(\\'lr\\', log_clf), (\\'svc\\', svcclf),\\n                                          (\\'svc_poly\\', svc_poly_clf)],\\n                              voting=\\'soft\\')\\nvoting_clf.fit(train_X, train_y)'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rnd_clf = RandomForestClassifier(n_estimators=1000,\n",
    "                                 max_leaf_nodes=32,\n",
    "                                 n_jobs=-1)\n",
    "rnd_clf.fit(train_X, train_y)\n",
    "\n",
    "'''svr_clf = SVR(kernel='rbf', gamma=2.0, C=10)\n",
    "svr_clf.fit(train_X, train_y)\n",
    "\n",
    "svc_clf = SVC(kernel='rbf', gamma=2.0, probability=True, C=10)\n",
    "svc_clf.fit(train_X, train_y)\n",
    "\n",
    "svc_poly_clf = SVC(kernel=\"poly\", probability=True, degree=3, coef0=1, C=5)\n",
    "svc_poly_clf.fit(train_X, train_y)\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"liblinear\", random_state=42)\n",
    "log_clf.fit(train_X, train_y)\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[('lr', log_clf), ('svc', svcclf),\n",
    "                                          ('svc_poly', svc_poly_clf)],\n",
    "                              voting='soft')\n",
    "voting_clf.fit(train_X, train_y)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.775"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = rnd_clf.predict(test_X)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 77 candidates, totalling 770 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 40 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  82 tasks      | elapsed:    3.5s\n",
      "[Parallel(n_jobs=-1)]: Done 285 tasks      | elapsed:    5.9s\n",
      "[Parallel(n_jobs=-1)]: Done 568 tasks      | elapsed:    9.5s\n",
      "[Parallel(n_jobs=-1)]: Done 770 out of 770 | elapsed:   13.4s finished\n",
      "/disk1/luoshen/software/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/utils/validation.py:724: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
       "                           decision_function_shape='ovr', degree=3,\n",
       "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
       "                           probability=False, random_state=None, shrinking=True,\n",
       "                           tol=0.001, verbose=False),\n",
       "             iid='warn', n_jobs=-1,\n",
       "             param_grid=[{'C': [1.0, 3.0, 10.0, 30.0, 100.0, 300.0, 1000.0],\n",
       "                          'degree': [2, 3, 4, 5, 6], 'kernel': ['poly']},\n",
       "                         {'C': [1.0, 3.0, 10.0, 30.0, 100.0, 300.0, 1000.0],\n",
       "                          'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0],\n",
       "                          'kernel': ['rbf']}],\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'degree': [2, 3, 4, 5, 6]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
    "    },\n",
    "]\n",
    "\n",
    "svc_clf_gs = SVC()\n",
    "grid_search = GridSearchCV(svc_clf_gs,\n",
    "                           param_grid,\n",
    "                           cv=10,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6835 {'C': 1.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.672 {'C': 1.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.6575 {'C': 1.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.64 {'C': 1.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.6245 {'C': 1.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.706 {'C': 3.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.703 {'C': 3.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.6885 {'C': 3.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.6715 {'C': 3.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.6575 {'C': 3.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.728 {'C': 10.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.7195 {'C': 10.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.709 {'C': 10.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.7 {'C': 10.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.69 {'C': 10.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.73 {'C': 30.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.726 {'C': 30.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.7275 {'C': 30.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.717 {'C': 30.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.708 {'C': 30.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.734 {'C': 100.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.733 {'C': 100.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.73 {'C': 100.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.7255 {'C': 100.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.7225 {'C': 100.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.7395 {'C': 300.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.743 {'C': 300.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.7405 {'C': 300.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.7325 {'C': 300.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.728 {'C': 300.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.7415 {'C': 1000.0, 'degree': 2, 'kernel': 'poly'}\n",
      "0.7435 {'C': 1000.0, 'degree': 3, 'kernel': 'poly'}\n",
      "0.744 {'C': 1000.0, 'degree': 4, 'kernel': 'poly'}\n",
      "0.7445 {'C': 1000.0, 'degree': 5, 'kernel': 'poly'}\n",
      "0.741 {'C': 1000.0, 'degree': 6, 'kernel': 'poly'}\n",
      "0.6925 {'C': 1.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.708 {'C': 1.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.727 {'C': 1.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.732 {'C': 1.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.723 {'C': 1.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.7165 {'C': 1.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.7105 {'C': 3.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.7275 {'C': 3.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.7325 {'C': 3.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.7365 {'C': 3.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.727 {'C': 3.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.7145 {'C': 3.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.7285 {'C': 10.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.732 {'C': 10.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.742 {'C': 10.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.742 {'C': 10.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.736 {'C': 10.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.727 {'C': 10.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.732 {'C': 30.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.7365 {'C': 30.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.742 {'C': 30.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.743 {'C': 30.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.7295 {'C': 30.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.7295 {'C': 30.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.738 {'C': 100.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.744 {'C': 100.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.7475 {'C': 100.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.745 {'C': 100.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.7405 {'C': 100.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.7215 {'C': 100.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.7405 {'C': 300.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.7455 {'C': 300.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.7555 {'C': 300.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.751 {'C': 300.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.7415 {'C': 300.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.711 {'C': 300.0, 'gamma': 3.0, 'kernel': 'rbf'}\n",
      "0.747 {'C': 1000.0, 'gamma': 0.01, 'kernel': 'rbf'}\n",
      "0.7525 {'C': 1000.0, 'gamma': 0.03, 'kernel': 'rbf'}\n",
      "0.7595 {'C': 1000.0, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "0.7525 {'C': 1000.0, 'gamma': 0.3, 'kernel': 'rbf'}\n",
      "0.7325 {'C': 1000.0, 'gamma': 1.0, 'kernel': 'rbf'}\n",
      "0.7025 {'C': 1000.0, 'gamma': 3.0, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "cvres = grid_search.cv_results_\n",
    "for score, params in zip(cvres[\"mean_test_score\"], cvres[\"params\"]):\n",
    "    print(score, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/disk1/luoshen/software/anaconda3/envs/nlp/lib/python3.6/site-packages/sklearn/svm/base.py:193: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVC(C=1000, cache_size=200, class_weight=None, coef0=1,\n",
       "    decision_function_shape='ovr', degree=2, gamma='auto_deprecated',\n",
       "    kernel='poly', max_iter=-1, probability=True, random_state=None,\n",
       "    shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svc_best = [0.6989130434782609, {'C': 1000.0, 'degree': 2, 'kernel': 'poly'}]\n",
    "\n",
    "\n",
    "train_X, test_X= train_X[:,:44], test_X[:,:44]\n",
    "\n",
    "\n",
    "svc_poly_clf = SVC(kernel=\"poly\", probability=True, degree=2, coef0=1, C=1000)\n",
    "svc_poly_clf.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7039337474120083"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = svc_poly_clf.predict(test_X)\n",
    "accuracy_score(test_y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {\n",
    "        'kernel': ['poly'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'degree': [2, 3, 4, 5, 6]\n",
    "    },\n",
    "    {\n",
    "        'kernel': ['rbf'],\n",
    "        'C': [1.0, 3.0, 10., 30., 100., 300., 1000.0],\n",
    "        'gamma': [0.01, 0.03, 0.1, 0.3, 1.0, 3.0]\n",
    "    },\n",
    "]\n",
    "\n",
    "svc_clf_gs = SVC()\n",
    "grid_search = GridSearchCV(svc_clf_gs,\n",
    "                           param_grid,\n",
    "                           cv=10,\n",
    "                           scoring='accuracy',\n",
    "                           verbose=2,\n",
    "                           n_jobs=-1)\n",
    "grid_search.fit(data, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19320, 69)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 8)                 528       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 537\n",
      "Trainable params: 537\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import keras.backend as K\n",
    "from keras import models, layers, regularizers, optimizers\n",
    "\n",
    "K.clear_session()\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_shape=(65,),))\n",
    "model.add(layers.Dense(1, activation='sigmoid',))\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=0.001),\n",
    "                loss='binary_crossentropy',\n",
    "                metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1800 samples, validate on 200 samples\n",
      "Epoch 1/100\n",
      "1800/1800 [==============================] - 1s 676us/step - loss: 0.7085 - acc: 0.5256 - val_loss: 0.6741 - val_acc: 0.6100\n",
      "Epoch 2/100\n",
      "1800/1800 [==============================] - 0s 60us/step - loss: 0.6469 - acc: 0.6628 - val_loss: 0.6697 - val_acc: 0.6000\n",
      "Epoch 3/100\n",
      "1800/1800 [==============================] - 0s 79us/step - loss: 0.6413 - acc: 0.6667 - val_loss: 0.6680 - val_acc: 0.6100\n",
      "Epoch 4/100\n",
      "1800/1800 [==============================] - 0s 66us/step - loss: 0.6381 - acc: 0.6578 - val_loss: 0.6673 - val_acc: 0.6350\n",
      "Epoch 5/100\n",
      "1800/1800 [==============================] - 0s 80us/step - loss: 0.6342 - acc: 0.6589 - val_loss: 0.6656 - val_acc: 0.6100\n",
      "Epoch 6/100\n",
      "1800/1800 [==============================] - 0s 267us/step - loss: 0.6319 - acc: 0.6650 - val_loss: 0.6600 - val_acc: 0.6050\n",
      "Epoch 7/100\n",
      "1800/1800 [==============================] - 0s 263us/step - loss: 0.6279 - acc: 0.6717 - val_loss: 0.6588 - val_acc: 0.6100\n",
      "Epoch 8/100\n",
      "1800/1800 [==============================] - 0s 77us/step - loss: 0.6250 - acc: 0.6694 - val_loss: 0.6584 - val_acc: 0.6100\n",
      "Epoch 9/100\n",
      "1800/1800 [==============================] - 0s 69us/step - loss: 0.6233 - acc: 0.6650 - val_loss: 0.6561 - val_acc: 0.6350\n",
      "Epoch 10/100\n",
      "1800/1800 [==============================] - 0s 96us/step - loss: 0.6207 - acc: 0.6767 - val_loss: 0.6518 - val_acc: 0.6200\n",
      "Epoch 11/100\n",
      "1800/1800 [==============================] - 0s 92us/step - loss: 0.6186 - acc: 0.6756 - val_loss: 0.6490 - val_acc: 0.6350\n",
      "Epoch 12/100\n",
      "1800/1800 [==============================] - 0s 71us/step - loss: 0.6171 - acc: 0.6711 - val_loss: 0.6470 - val_acc: 0.6500\n",
      "Epoch 13/100\n",
      "1800/1800 [==============================] - 0s 72us/step - loss: 0.6145 - acc: 0.6800 - val_loss: 0.6468 - val_acc: 0.6750\n",
      "Epoch 14/100\n",
      "1800/1800 [==============================] - 0s 114us/step - loss: 0.6133 - acc: 0.6867 - val_loss: 0.6495 - val_acc: 0.6200\n",
      "Epoch 15/100\n",
      "1800/1800 [==============================] - 0s 70us/step - loss: 0.6120 - acc: 0.6750 - val_loss: 0.6419 - val_acc: 0.6250\n",
      "Epoch 16/100\n",
      "1800/1800 [==============================] - 0s 142us/step - loss: 0.6089 - acc: 0.6844 - val_loss: 0.6411 - val_acc: 0.6400\n",
      "Epoch 17/100\n",
      "1800/1800 [==============================] - 0s 163us/step - loss: 0.6067 - acc: 0.6778 - val_loss: 0.6388 - val_acc: 0.6450\n",
      "Epoch 18/100\n",
      "1800/1800 [==============================] - 0s 65us/step - loss: 0.6050 - acc: 0.6806 - val_loss: 0.6359 - val_acc: 0.6400\n",
      "Epoch 19/100\n",
      "1800/1800 [==============================] - 0s 64us/step - loss: 0.6037 - acc: 0.6911 - val_loss: 0.6386 - val_acc: 0.6450\n",
      "Epoch 20/100\n",
      "1800/1800 [==============================] - 0s 99us/step - loss: 0.6025 - acc: 0.6889 - val_loss: 0.6338 - val_acc: 0.6550\n",
      "Epoch 21/100\n",
      "1800/1800 [==============================] - 0s 195us/step - loss: 0.6004 - acc: 0.6911 - val_loss: 0.6305 - val_acc: 0.6550\n",
      "Epoch 22/100\n",
      "1800/1800 [==============================] - 0s 128us/step - loss: 0.5995 - acc: 0.6950 - val_loss: 0.6387 - val_acc: 0.6350\n",
      "Epoch 23/100\n",
      "1800/1800 [==============================] - 0s 65us/step - loss: 0.5984 - acc: 0.6844 - val_loss: 0.6288 - val_acc: 0.6500\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "                keras.callbacks.EarlyStopping(\n",
    "                monitor='val_acc',\n",
    "                patience=10,\n",
    "                ),\n",
    "keras.callbacks.ModelCheckpoint(\n",
    "                filepath='my_model.h5',\n",
    "                monitor='val_loss',\n",
    "                save_best_only=True,\n",
    "                )\n",
    "]\n",
    "\n",
    "history = model.fit(data, target, batch_size=128, epochs=100, verbose = 1, \n",
    "                    validation_split=0.1, callbacks=callbacks_list, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data[:,:44] \n",
    "data2 = data[:,-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.concatenate((data1,data2),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>gender</th>\n",
       "      <th>word ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.289545</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.940899</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.502463e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.347826e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.133531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.541787</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.824561e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1.165503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.419355e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.500001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.810930</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.154151</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.500000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.000001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.999998e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.666668e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.815642</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.048711e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.476777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.758065e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.929878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.177419e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.205003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.069767e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.710878</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.051661e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.708804</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1.466337</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.857143e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.500000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2.524928</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.600000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1.284394</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.590909e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.640467</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.774194e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.734601</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.260870e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.519416</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.320000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.439846</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.636364e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1.612434</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.846154e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19290</th>\n",
       "      <td>0.366353</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.303030e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19291</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000001e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19292</th>\n",
       "      <td>0.428725</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19293</th>\n",
       "      <td>2.708050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19294</th>\n",
       "      <td>0.751326</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.543478e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19295</th>\n",
       "      <td>1.457325</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.352941e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19296</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19297</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.076924e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19298</th>\n",
       "      <td>0.346574</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.129032e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19299</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19300</th>\n",
       "      <td>1.384942</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.082111e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19301</th>\n",
       "      <td>0.443866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.646465e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19302</th>\n",
       "      <td>0.551730</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.021352e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19303</th>\n",
       "      <td>1.178655</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19304</th>\n",
       "      <td>0.287682</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.714286e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19305</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000002e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19306</th>\n",
       "      <td>2.639057</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.888889e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19307</th>\n",
       "      <td>1.848927</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.047619e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19308</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.666667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19309</th>\n",
       "      <td>0.981111</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.530612e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19310</th>\n",
       "      <td>0.662537</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.605634e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19311</th>\n",
       "      <td>2.322195</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.512195e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19312</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.166667e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19313</th>\n",
       "      <td>0.387717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.411765e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19314</th>\n",
       "      <td>1.170369</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.824176e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19315</th>\n",
       "      <td>1.189811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.750000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19316</th>\n",
       "      <td>0.207639</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.187500e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19317</th>\n",
       "      <td>0.524332</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.183206e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19318</th>\n",
       "      <td>0.693050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.388889e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19319</th>\n",
       "      <td>2.564949</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.333333e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>19320 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           bias  gender    word ratio\n",
       "0      0.289545     0.0  5.000000e-01\n",
       "1      0.000000     0.0  1.000000e+00\n",
       "2      0.940899     0.0  6.502463e-01\n",
       "3      0.810930     0.0  4.347826e-01\n",
       "4      0.133531     0.0  5.000000e-01\n",
       "5      0.541787     0.0  5.824561e-01\n",
       "6      1.165503     0.0  7.419355e-01\n",
       "7      0.000000     0.0  7.500001e-01\n",
       "8      0.810930     0.0  6.000000e-01\n",
       "9      0.154151     0.0  5.500000e-01\n",
       "10     0.000000     0.0  4.000001e-01\n",
       "11     0.000000     0.0  4.999998e-07\n",
       "12     0.000000     0.0  6.666668e-01\n",
       "13     0.815642     0.0  7.048711e-01\n",
       "14     0.476777     0.0  4.758065e-01\n",
       "15     0.929878     0.0  7.177419e-01\n",
       "16     2.205003     0.0  9.069767e-01\n",
       "17     0.710878     0.0  6.051661e-01\n",
       "18     0.708804     0.0  6.530612e-01\n",
       "19     0.000000     0.0  5.000000e-01\n",
       "20     1.466337     0.0  2.857143e-01\n",
       "21     0.000000     0.0  9.500000e-01\n",
       "22     2.524928     0.0  9.600000e-01\n",
       "23     1.284394     0.0  6.590909e-01\n",
       "24     0.000000     0.0  5.000000e-01\n",
       "25     0.640467     0.0  6.774194e-01\n",
       "26     1.734601     0.0  8.260870e-01\n",
       "27     0.519416     0.0  4.320000e-01\n",
       "28     0.439846     0.0  3.636364e-01\n",
       "29     1.612434     0.0  8.846154e-01\n",
       "...         ...     ...           ...\n",
       "19290  0.366353     1.0  5.303030e-01\n",
       "19291  0.000000     1.0  5.000001e-01\n",
       "19292  0.428725     1.0  5.000000e-01\n",
       "19293  2.708050     1.0  1.000000e+00\n",
       "19294  0.751326     1.0  5.543478e-01\n",
       "19295  1.457325     1.0  7.352941e-01\n",
       "19296  0.000000     1.0  8.750000e-01\n",
       "19297  0.000000     1.0  3.076924e-01\n",
       "19298  0.346574     1.0  6.129032e-01\n",
       "19299  0.000000     1.0  7.000000e-01\n",
       "19300  1.384942     1.0  2.082111e-01\n",
       "19301  0.443866     1.0  4.646465e-01\n",
       "19302  0.551730     1.0  4.021352e-01\n",
       "19303  1.178655     1.0  6.666667e-01\n",
       "19304  0.287682     1.0  5.714286e-01\n",
       "19305  0.000000     1.0  2.000002e-01\n",
       "19306  2.639057     1.0  8.888889e-01\n",
       "19307  1.848927     1.0  9.047619e-01\n",
       "19308  0.000000     1.0  8.666667e-01\n",
       "19309  0.981111     1.0  6.530612e-01\n",
       "19310  0.662537     1.0  7.605634e-01\n",
       "19311  2.322195     1.0  9.512195e-01\n",
       "19312  0.000000     1.0  9.166667e-01\n",
       "19313  0.387717     1.0  4.411765e-01\n",
       "19314  1.170369     1.0  7.824176e-01\n",
       "19315  1.189811     1.0  7.750000e-01\n",
       "19316  0.207639     1.0  7.187500e-01\n",
       "19317  0.524332     1.0  6.183206e-01\n",
       "19318  0.693050     1.0  6.388889e-01\n",
       "19319  2.564949     1.0  8.333333e-01\n",
       "\n",
       "[19320 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_txt = pd.read_csv('blogs_genderbias.csv')\n",
    "df_per_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19320, 46)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall.to_csv('blogs_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./2000novel/female/\n",
      "Files: 1000\n"
     ]
    }
   ],
   "source": [
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './2000novel/female/'\n",
    "    else:\n",
    "        txtDir = './2000novel/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(blogs_gender))\n",
    "    for m in blogs_gender:\n",
    "        text = gettext(txtDir + m)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        CorpusPOS(sentences)\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "\n",
    "(a, b, c, d, e, f, g) = calc_probabilities(cPOS)\n",
    "q1_output(a, b, c, d, e, f, g)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./postprocess_2000novel/female/\n",
      "Files: 1000\n",
      "Processing gender: ./postprocess_2000novel/male/\n",
      "Files: 1000\n"
     ]
    }
   ],
   "source": [
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_2000novel/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_2000novel/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(blogs_gender))\n",
    "    for m in blogs_gender:\n",
    "        name = txtDir + m\n",
    "        text = gettext(name)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        sentences = nltk.sent_tokenize(text)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        words_l = wordlemmatize(tags)\n",
    "\n",
    "        F_feature = F_measure(tags)\n",
    "        GRF_feature = Gender_Preferential_Features(words_l)\n",
    "        WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "        textTags = \"\"\n",
    "        for word, tag in tags_s:\n",
    "            if tag in tagList:\n",
    "                textTags = textTags + tag + \" \"\n",
    "\n",
    "        POS_feature = []\n",
    "\n",
    "        for feature in posFeatures:\n",
    "            if feature in textTags:\n",
    "                POS_feature.append(1)\n",
    "            else:\n",
    "                POS_feature.append(0)\n",
    "        names.append(name)\n",
    "        F_features.append(F_feature)\n",
    "        GRF_features.append(GRF_feature)\n",
    "        WC_features.append(WC_feature)\n",
    "        POS_features.append(POS_feature)\n",
    "        labels.append(gender)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getsingle(features, n):\n",
    "    single = []\n",
    "    for item in features:\n",
    "        single.append(item[n])\n",
    "    return single\n",
    "\n",
    "\n",
    "WC_features_l = []\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "GRF_features_l = []\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "POS_features_l = []\n",
    "for i in range(len(POS_features[0])):\n",
    "    n = i\n",
    "    POS_features_l.append(getsingle(POS_features, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(POS_features[0])):\n",
    "    key = 'POS_' + str(i + 1)\n",
    "    value = POS_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_novel.csv',index = False)\n",
    "#allofall = pd.read_csv('allofall.csv')\n",
    "#df_per_txt = pd.read_csv('blogs_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bias</th>\n",
       "      <th>gender</th>\n",
       "      <th>word ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.542212</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.454310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.585030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.607524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.485678</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.571576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.600768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.370205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.495262</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.569502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.433581</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.449752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.549476</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.423285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.027705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.714715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.102950</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.757576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.768278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.537118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.312265</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.922502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.591201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.849057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1.562984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.839650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2.216278</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.918900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1.109771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.703225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.747564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.620390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.133531</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.434783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.419223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.489972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.630149</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.384338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.591871</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.390835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.941341</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.286059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1.077038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.482187</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1.185201</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.235099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.986534</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.743956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.495372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.422626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.451704</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.564756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.644259</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.618114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.474742</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.524012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>0.486744</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.535762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971</th>\n",
       "      <td>2.582756</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1972</th>\n",
       "      <td>0.914001</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.694243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1973</th>\n",
       "      <td>0.397472</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.538297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1974</th>\n",
       "      <td>2.547967</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1975</th>\n",
       "      <td>2.600501</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.961649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1976</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1977</th>\n",
       "      <td>1.443123</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>1.661088</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.820970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1979</th>\n",
       "      <td>2.488692</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.940269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1980</th>\n",
       "      <td>0.551592</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.622338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1981</th>\n",
       "      <td>1.056747</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1982</th>\n",
       "      <td>0.453866</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.415385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983</th>\n",
       "      <td>1.622329</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.843959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1984</th>\n",
       "      <td>0.493593</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.520677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1985</th>\n",
       "      <td>2.409014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.932072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1986</th>\n",
       "      <td>1.097404</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.732474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>0.745071</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.665455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1988</th>\n",
       "      <td>2.807041</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.967117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>0.917455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.706456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1990</th>\n",
       "      <td>1.567717</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.846995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1991</th>\n",
       "      <td>1.278340</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.783641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1992</th>\n",
       "      <td>2.023243</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.899049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993</th>\n",
       "      <td>0.598831</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.594125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994</th>\n",
       "      <td>0.499128</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.463158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>0.576652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.585068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>2.756723</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.963016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>1.844440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.950000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>2.101042</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.108280</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bias  gender  word ratio\n",
       "0     0.542212     0.0    0.454310\n",
       "1     0.585030     0.0    0.607524\n",
       "2     0.485678     0.0    0.571576\n",
       "3     0.600768     0.0    0.370205\n",
       "4     0.495262     0.0    0.569502\n",
       "5     0.433581     0.0    0.449752\n",
       "6     0.549476     0.0    0.423285\n",
       "7     1.027705     0.0    0.714715\n",
       "8     1.102950     0.0    0.757576\n",
       "9     0.768278     0.0    0.537118\n",
       "10    2.312265     0.0    0.922502\n",
       "11    1.591201     0.0    0.849057\n",
       "12    1.562984     0.0    0.839650\n",
       "13    2.216278     0.0    0.918900\n",
       "14    0.742531     0.0    0.363095\n",
       "15    1.109771     0.0    0.703225\n",
       "16    0.747564     0.0    0.620390\n",
       "17    0.133531     0.0    0.434783\n",
       "18    0.419223     0.0    0.489972\n",
       "19    0.630149     0.0    0.384338\n",
       "20    0.591871     0.0    0.390835\n",
       "21    0.941341     0.0    0.286059\n",
       "22    1.077038     0.0    0.740458\n",
       "23    0.482187     0.0    0.524533\n",
       "24    1.185201     0.0    0.235099\n",
       "25    0.986534     0.0    0.743956\n",
       "26    0.495372     0.0    0.422626\n",
       "27    0.451704     0.0    0.564756\n",
       "28    0.644259     0.0    0.618114\n",
       "29    0.474742     0.0    0.524012\n",
       "...        ...     ...         ...\n",
       "1970  0.486744     1.0    0.535762\n",
       "1971  2.582756     1.0    0.961783\n",
       "1972  0.914001     1.0    0.694243\n",
       "1973  0.397472     1.0    0.538297\n",
       "1974  2.547967     1.0    0.950538\n",
       "1975  2.600501     1.0    0.961649\n",
       "1976  0.000000     1.0    1.000000\n",
       "1977  1.443123     1.0    0.820024\n",
       "1978  1.661088     1.0    0.820970\n",
       "1979  2.488692     1.0    0.940269\n",
       "1980  0.551592     1.0    0.622338\n",
       "1981  1.056747     1.0    0.745020\n",
       "1982  0.453866     1.0    0.415385\n",
       "1983  1.622329     1.0    0.843959\n",
       "1984  0.493593     1.0    0.520677\n",
       "1985  2.409014     1.0    0.932072\n",
       "1986  1.097404     1.0    0.732474\n",
       "1987  0.745071     1.0    0.665455\n",
       "1988  2.807041     1.0    0.967117\n",
       "1989  0.917455     1.0    0.706456\n",
       "1990  1.567717     1.0    0.846995\n",
       "1991  1.278340     1.0    0.783641\n",
       "1992  2.023243     1.0    0.899049\n",
       "1993  0.598831     1.0    0.594125\n",
       "1994  0.499128     1.0    0.463158\n",
       "1995  0.000000     1.0    1.000000\n",
       "1996  0.576652     1.0    0.585068\n",
       "1997  2.756723     1.0    0.963016\n",
       "1998  1.844440     1.0    0.950000\n",
       "1999  2.101042     1.0    0.108280\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_per_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_per_txt = pd.read_csv('novel_genderbias.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['bias'], allofall['word ratio'] = df_per_txt['bias'], df_per_txt['word ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#allofall.to_csv('novel_features.csv',index=False)\n",
    "allofall = pd.read_csv('novel_features.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
