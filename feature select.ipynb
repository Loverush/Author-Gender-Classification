{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T10:04:24.295602Z",
     "start_time": "2019-08-17T10:04:23.817845Z"
    },
    "init_cell": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, log_loss\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from MLFeatureSelection import sequence_selection, importance_selection, coherence_selection,tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T10:04:24.465736Z",
     "start_time": "2019-08-17T10:04:24.297208Z"
    },
    "init_cell": true
   },
   "outputs": [],
   "source": [
    "def lossfunction(y_pred, y_test):\n",
    "    \"\"\"define your own loss function with y_pred and y_test\n",
    "    return score\n",
    "    \"\"\"\n",
    "    return 100 * accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "def validate(X, y, features, clf, lossfunction):\n",
    "    \"\"\"define your own validation function with 5 parameters\n",
    "    input as X, y, features, clf, lossfunction\n",
    "    clf is set by SetClassifier()\n",
    "    lossfunction is import earlier\n",
    "    features will be generate automatically\n",
    "    function return score and trained classfier\n",
    "    \"\"\"\n",
    "    train_X, test_X, train_y, test_y = train_test_split(X[features],\n",
    "                                                        y,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    clf.fit(train_X, train_y)\n",
    "    scores = cross_val_score(clf, X[features], y, cv=5)\n",
    "    #y_pred = clf.predict(test_X)\n",
    "    #score = lossfunction(test_y, y_pred)\n",
    "    score = scores.mean()\n",
    "    return score, clf\n",
    "\n",
    "\n",
    "def add(x, y):\n",
    "    return x + y\n",
    "\n",
    "\n",
    "def substract(x, y):\n",
    "    return x - y\n",
    "\n",
    "\n",
    "def times(x, y):\n",
    "    return x * y\n",
    "\n",
    "\n",
    "def divide(x, y):\n",
    "    return (x + 0.001) / (y + 0.001)\n",
    "\n",
    "\n",
    "def sq(x, y):\n",
    "    return x**2\n",
    "\n",
    "\n",
    "CrossMethod = {\n",
    "    #'+': add,\n",
    "    #'-': substract,\n",
    "    '*': times,\n",
    "    #'/': divide,\n",
    "    #'^': sq,\n",
    "}\n",
    "\n",
    "\n",
    "def seq(df, f, notusable, estimator):\n",
    "    sf = sequence_selection.Select(\n",
    "        Sequence=True, Random=False,\n",
    "        Cross=True)  #initialized selector with wanted process\n",
    "    sf.ImportDF(df, label='label')  #import dataframe and define the label name\n",
    "    sf.ImportLossFunction(\n",
    "        lossfunction,\n",
    "        direction='ascend')  #import loosfunction and improve direction\n",
    "    sf.ImportCrossMethod(CrossMethod)  #import dictionary of cross method\n",
    "    sf.InitialNonTrainableFeatures(\n",
    "        notusable)  #define features that are not trainable\n",
    "    sf.InitialFeatures(f)  #define list initial features combination\n",
    "    sf.GenerateCol()  #generate candidate features list\n",
    "    sf.clf = estimator  #define selected estimator\n",
    "    sf.SetLogFile('record_seq.log')  #set the log file name\n",
    "    return sf.run(validate)  #start running\n",
    "\n",
    "\n",
    "def imp(df, f, estimator):\n",
    "    sf = importance_selection.Select()  #initialized selector\n",
    "    sf.ImportDF(df, label='label')  #import dataset\n",
    "    sf.ImportLossFunction(\n",
    "        lossfunction,\n",
    "        direction='ascend')  #import loosfunction and improve direction\n",
    "    sf.InitialFeatures(f)  #define list initial features combination\n",
    "    sf.SelectRemoveMode(\n",
    "        batch=1)  #define remove features quantity each iteration\n",
    "    sf.clf = estimator  #define selected estimator\n",
    "    sf.SetLogFile('record_imp.log')  #set the log file name\n",
    "    return sf.run(validate)  #start running\n",
    "\n",
    "\n",
    "def coh(df, f, estimator):\n",
    "    sf = coherence_selection.Select()  #initialized selector\n",
    "    sf.ImportDF(df, label='label')  #import dataset\n",
    "    sf.ImportLossFunction(\n",
    "        lossfunction,\n",
    "        direction='ascend')  #import loosfunction and improve direction\n",
    "    sf.InitialFeatures(f)  #define list initial features combination\n",
    "    sf.SelectRemoveMode(\n",
    "        batch=1, lowerbound=0.5\n",
    "    )  #define remove features quantity each iteration and selection threshold\n",
    "    sf.clf = estimator  #define selected estimator\n",
    "    sf.SetLogFile('record_coh.log')  #set the log file name\n",
    "    return sf.run(validate)  #start running\n",
    "\n",
    "\n",
    "def run(df, bf):\n",
    "    notusable = ['label']  #not trainable features\n",
    "    f = bf  #initial features combination\n",
    "    clf = RandomForestClassifier(n_estimators=800,\n",
    "                                 max_leaf_nodes=64,\n",
    "                                 n_jobs=-1)\n",
    "    uf = f[:]\n",
    "    print('sequence selection')\n",
    "    uf = seq(df, uf, notusable, clf)\n",
    "    print('importance selection')\n",
    "    uf = imp(df, uf, clf)\n",
    "    print('coherence selection')\n",
    "    uf = coh(df, uf, clf)\n",
    "    return uf\n",
    "\n",
    "\n",
    "df = pd.read_csv('newnewnew.csv')\n",
    "df = df.drop(columns=['name', 'word count'])\n",
    "for i in range(df.shape[1]):\n",
    "    df.iloc[:, i] = preprocessing.scale(df.iloc[:, i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T10:34:24.566590Z",
     "start_time": "2019-08-17T10:04:32.259730Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence selection\n",
      "Features Quantity Limit: inf\n",
      "Time Limit: inf min(s)\n",
      "100000000\n",
      "test performance of initial features combination\n",
      "Mean loss: 0.7894\n",
      "--------------------start greedy--------------------\n",
      "word ratio\n",
      "GRF_8\n",
      "WC_2\n",
      "GRF_3\n",
      "WC_7\n",
      "base_10\n",
      "base_9\n",
      "WC_9\n",
      "WC_22\n",
      "base_13\n",
      "******************** 11 round ********************\n",
      "F_feature\n",
      "0/42\n",
      "Mean loss: 0.7846\n",
      "WC_1\n",
      "1/42\n",
      "Mean loss: 0.7862000000000001\n",
      "WC_3\n",
      "2/42\n",
      "Mean loss: 0.7858\n",
      "WC_4\n",
      "3/42\n",
      "Mean loss: 0.7876\n",
      "WC_5\n",
      "4/42\n",
      "Mean loss: 0.7852\n",
      "WC_6\n",
      "5/42\n",
      "Mean loss: 0.7868\n",
      "WC_8\n",
      "6/42\n",
      "Mean loss: 0.7872000000000001\n",
      "WC_10\n",
      "7/42\n",
      "Mean loss: 0.7849999999999999\n",
      "WC_11\n",
      "8/42\n",
      "Mean loss: 0.7858\n",
      "WC_12\n",
      "9/42\n",
      "Mean loss: 0.7858\n",
      "WC_13\n",
      "10/42\n",
      "Mean loss: 0.7868\n",
      "WC_14\n",
      "11/42\n",
      "Mean loss: 0.788\n",
      "WC_15\n",
      "12/42\n",
      "Mean loss: 0.7847999999999999\n",
      "WC_16\n",
      "13/42\n",
      "Mean loss: 0.7862\n",
      "WC_17\n",
      "14/42\n",
      "Mean loss: 0.7832\n",
      "WC_18\n",
      "15/42\n",
      "Mean loss: 0.7876000000000001\n",
      "WC_19\n",
      "16/42\n",
      "Mean loss: 0.7878000000000001\n",
      "WC_20\n",
      "17/42\n",
      "Mean loss: 0.7882\n",
      "WC_21\n",
      "18/42\n",
      "Mean loss: 0.7854000000000001\n",
      "WC_23\n",
      "19/42\n",
      "Mean loss: 0.7878000000000001\n",
      "GRF_1\n",
      "20/42\n",
      "Mean loss: 0.7874000000000001\n",
      "GRF_2\n",
      "21/42\n",
      "Mean loss: 0.7870000000000001\n",
      "GRF_4\n",
      "22/42\n",
      "Mean loss: 0.7864\n",
      "GRF_5\n",
      "23/42\n",
      "Mean loss: 0.7852000000000001\n",
      "GRF_6\n",
      "24/42\n",
      "Mean loss: 0.7866000000000001\n",
      "GRF_7\n",
      "25/42\n",
      "Mean loss: 0.7878000000000001\n",
      "GRF_9\n",
      "26/42\n",
      "Mean loss: 0.7838\n",
      "GRF_10\n",
      "27/42\n",
      "Mean loss: 0.786\n",
      "bias\n",
      "28/42\n",
      "Mean loss: 0.7858\n",
      "base_1\n",
      "29/42\n",
      "Mean loss: 0.7864000000000001\n",
      "base_2\n",
      "30/42\n",
      "Mean loss: 0.7849999999999999\n",
      "base_3\n",
      "31/42\n",
      "Mean loss: 0.7858\n",
      "base_4\n",
      "32/42\n",
      "Mean loss: 0.7848\n",
      "base_5\n",
      "33/42\n",
      "Mean loss: 0.7868\n",
      "base_6\n",
      "34/42\n",
      "Mean loss: 0.7854\n",
      "base_7\n",
      "35/42\n",
      "Mean loss: 0.784\n",
      "base_8\n",
      "36/42\n",
      "Mean loss: 0.7876000000000001\n",
      "base_11\n",
      "37/42\n",
      "Mean loss: 0.7882\n",
      "base_12\n",
      "38/42\n",
      "Mean loss: 0.7864000000000001\n",
      "base_14\n",
      "39/42\n",
      "Mean loss: 0.7838\n",
      "base_15\n",
      "40/42\n",
      "Mean loss: 0.7856000000000001\n",
      "base_16\n",
      "41/42\n",
      "Mean loss: 0.7847999999999999\n",
      "word ratio\n",
      "reverse 0/9\n",
      "Mean loss: 0.745\n",
      "GRF_8\n",
      "reverse 1/9\n",
      "Mean loss: 0.785\n",
      "WC_2\n",
      "reverse 2/9\n",
      "Mean loss: 0.7852000000000001\n",
      "GRF_3\n",
      "reverse 3/9\n",
      "Mean loss: 0.7742\n",
      "WC_7\n",
      "reverse 4/9\n",
      "Mean loss: 0.7844000000000001\n",
      "base_10\n",
      "reverse 5/9\n",
      "Mean loss: 0.7834\n",
      "base_9\n",
      "reverse 6/9\n",
      "Mean loss: 0.7837999999999999\n",
      "WC_9\n",
      "reverse 7/9\n",
      "Mean loss: 0.7862\n",
      "WC_22\n",
      "reverse 8/9\n",
      "Mean loss: 0.7904\n",
      "******************** 10 round ********************\n",
      "F_feature\n",
      "0/43\n",
      "Mean loss: 0.7836000000000001\n",
      "WC_1\n",
      "1/43\n",
      "Mean loss: 0.787\n",
      "WC_3\n",
      "2/43\n",
      "Mean loss: 0.7856\n",
      "WC_4\n",
      "3/43\n",
      "Mean loss: 0.7882\n",
      "WC_5\n",
      "4/43\n",
      "Mean loss: 0.7864000000000001\n",
      "WC_6\n",
      "5/43\n",
      "Mean loss: 0.7882\n",
      "WC_8\n",
      "6/43\n",
      "Mean loss: 0.7864000000000001\n",
      "WC_10\n",
      "7/43\n",
      "Mean loss: 0.7866000000000002\n",
      "WC_11\n",
      "8/43\n",
      "Mean loss: 0.7866000000000001\n",
      "WC_12\n",
      "9/43\n",
      "Mean loss: 0.785\n",
      "WC_13\n",
      "10/43\n",
      "Mean loss: 0.7892\n",
      "WC_14\n",
      "11/43\n",
      "Mean loss: 0.7866000000000002\n",
      "WC_15\n",
      "12/43\n",
      "Mean loss: 0.7859999999999999\n",
      "WC_16\n",
      "13/43\n",
      "Mean loss: 0.7842\n",
      "WC_17\n",
      "14/43\n",
      "Mean loss: 0.7832\n",
      "WC_18\n",
      "15/43\n",
      "Mean loss: 0.7876000000000001\n",
      "WC_19\n",
      "16/43\n",
      "Mean loss: 0.7892\n",
      "WC_20\n",
      "17/43\n",
      "Mean loss: 0.7872\n",
      "WC_21\n",
      "18/43\n",
      "Mean loss: 0.7884\n",
      "WC_23\n",
      "19/43\n",
      "Mean loss: 0.7882\n",
      "GRF_1\n",
      "20/43\n",
      "Mean loss: 0.7874000000000001\n",
      "GRF_2\n",
      "21/43\n",
      "Mean loss: 0.788\n",
      "GRF_4\n",
      "22/43\n",
      "Mean loss: 0.7882\n",
      "GRF_5\n",
      "23/43\n",
      "Mean loss: 0.7868\n",
      "GRF_6\n",
      "24/43\n",
      "Mean loss: 0.7882\n",
      "GRF_7\n",
      "25/43\n",
      "Mean loss: 0.7878000000000001\n",
      "GRF_9\n",
      "26/43\n",
      "Mean loss: 0.7872000000000001\n",
      "GRF_10\n",
      "27/43\n",
      "Mean loss: 0.7858\n",
      "bias\n",
      "28/43\n",
      "Mean loss: 0.7858\n",
      "base_1\n",
      "29/43\n",
      "Mean loss: 0.7872\n",
      "base_2\n",
      "30/43\n",
      "Mean loss: 0.7844000000000001\n",
      "base_3\n",
      "31/43\n",
      "Mean loss: 0.7882\n",
      "base_4\n",
      "32/43\n",
      "Mean loss: 0.7854\n",
      "base_5\n",
      "33/43\n",
      "Mean loss: 0.7866000000000001\n",
      "base_6\n",
      "34/43\n",
      "Mean loss: 0.7859999999999999\n",
      "base_7\n",
      "35/43\n",
      "Mean loss: 0.784\n",
      "base_8\n",
      "36/43\n",
      "Mean loss: 0.7872\n",
      "base_11\n",
      "37/43\n",
      "Mean loss: 0.7882\n",
      "base_12\n",
      "38/43\n",
      "Mean loss: 0.7876000000000001\n",
      "base_14\n",
      "39/43\n",
      "Mean loss: 0.7851999999999999\n",
      "base_15\n",
      "40/43\n",
      "Mean loss: 0.7876\n",
      "base_16\n",
      "41/43\n",
      "Mean loss: 0.7864000000000001\n",
      "WC_22\n",
      "42/43\n",
      "Mean loss: 0.788\n",
      "word ratio\n",
      "reverse 0/8\n",
      "Mean loss: 0.7394000000000001\n",
      "GRF_8\n",
      "reverse 1/8\n",
      "Mean loss: 0.783\n",
      "WC_2\n",
      "reverse 2/8\n",
      "Mean loss: 0.7836\n",
      "GRF_3\n",
      "reverse 3/8\n",
      "Mean loss: 0.7741999999999999\n",
      "WC_7\n",
      "reverse 4/8\n",
      "Mean loss: 0.7822\n",
      "base_10\n",
      "reverse 5/8\n",
      "Mean loss: 0.7834\n",
      "base_9\n",
      "reverse 6/8\n",
      "Mean loss: 0.7808\n",
      "WC_9\n",
      "reverse 7/8\n",
      "Mean loss: 0.7848\n",
      "--------------------complete greedy--------------------\n",
      "random select starts with:\n",
      " ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13']\n",
      " score: 0.7904\n",
      "small cycle cross\n",
      "0/81\n",
      "Mean loss: 0.7878000000000001\n",
      "1/81\n",
      "Mean loss: 0.7876000000000001\n",
      "2/81\n",
      "Mean loss: 0.7889999999999999\n",
      "3/81\n",
      "Mean loss: 0.7868\n",
      "4/81\n",
      "Mean loss: 0.7862\n",
      "5/81\n",
      "Mean loss: 0.7878000000000001\n",
      "6/81\n",
      "Mean loss: 0.7859999999999999\n",
      "7/81\n",
      "Mean loss: 0.7854\n",
      "8/81\n",
      "Mean loss: 0.7866\n",
      "9/81\n",
      "Mean loss: 0.7876000000000001\n",
      "10/81\n",
      "Mean loss: 0.7874000000000001\n",
      "11/81\n",
      "Mean loss: 0.7892\n",
      "12/81\n",
      "Mean loss: 0.7872\n",
      "13/81\n",
      "Mean loss: 0.789\n",
      "14/81\n",
      "Mean loss: 0.7884\n",
      "15/81\n",
      "Mean loss: 0.7868\n",
      "16/81\n",
      "Mean loss: 0.7892000000000001\n",
      "17/81\n",
      "Mean loss: 0.787\n",
      "18/81\n",
      "Mean loss: 0.7878000000000001\n",
      "19/81\n",
      "Mean loss: 0.7872000000000001\n",
      "20/81\n",
      "Mean loss: 0.7876000000000001\n",
      "21/81\n",
      "Mean loss: 0.7882\n",
      "22/81\n",
      "Mean loss: 0.7892\n",
      "23/81\n",
      "Mean loss: 0.7882\n",
      "24/81\n",
      "Mean loss: 0.788\n",
      "25/81\n",
      "Mean loss: 0.7888\n",
      "26/81\n",
      "Mean loss: 0.7860000000000001\n",
      "27/81\n",
      "Mean loss: 0.7864\n",
      "28/81\n",
      "Mean loss: 0.7886000000000001\n",
      "29/81\n",
      "Mean loss: 0.7898\n",
      "30/81\n",
      "Mean loss: 0.7878\n",
      "31/81\n",
      "Mean loss: 0.7892\n",
      "32/81\n",
      "Mean loss: 0.7862\n",
      "33/81\n",
      "Mean loss: 0.789\n",
      "34/81\n",
      "Mean loss: 0.7874000000000001\n",
      "35/81\n",
      "Mean loss: 0.789\n",
      "36/81\n",
      "Mean loss: 0.7869999999999999\n",
      "37/81\n",
      "Mean loss: 0.7892\n",
      "38/81\n",
      "Mean loss: 0.7882\n",
      "39/81\n",
      "Mean loss: 0.7898\n",
      "40/81\n",
      "Mean loss: 0.7884\n",
      "41/81\n",
      "Mean loss: 0.7894\n",
      "42/81\n",
      "Mean loss: 0.789\n",
      "43/81\n",
      "Mean loss: 0.789\n",
      "44/81\n",
      "Mean loss: 0.7878000000000001\n",
      "45/81\n",
      "Mean loss: 0.788\n",
      "46/81\n",
      "Mean loss: 0.7908\n",
      "47/81\n",
      "Mean loss: 0.7884\n",
      "48/81\n",
      "Mean loss: 0.788\n",
      "49/81\n",
      "Mean loss: 0.7891999999999999\n",
      "50/81\n",
      "Mean loss: 0.785\n",
      "51/81\n",
      "Mean loss: 0.7854000000000001\n",
      "52/81\n",
      "Mean loss: 0.7899999999999999\n",
      "53/81\n",
      "Mean loss: 0.7878000000000001\n",
      "54/81\n",
      "Mean loss: 0.7888000000000001\n",
      "55/81\n",
      "Mean loss: 0.7866\n",
      "56/81\n",
      "Mean loss: 0.789\n",
      "57/81\n",
      "Mean loss: 0.7870000000000001\n",
      "58/81\n",
      "Mean loss: 0.7902000000000001\n",
      "59/81\n",
      "Mean loss: 0.7884\n",
      "60/81\n",
      "Mean loss: 0.7886000000000001\n",
      "61/81\n",
      "Mean loss: 0.7878000000000001\n",
      "62/81\n",
      "Mean loss: 0.7886000000000001\n",
      "63/81\n",
      "Mean loss: 0.7882\n",
      "64/81\n",
      "Mean loss: 0.7878000000000001\n",
      "65/81\n",
      "Mean loss: 0.7896000000000001\n",
      "66/81\n",
      "Mean loss: 0.7878000000000001\n",
      "67/81\n",
      "Mean loss: 0.7882\n",
      "68/81\n",
      "Mean loss: 0.7872\n",
      "69/81\n",
      "Mean loss: 0.788\n",
      "70/81\n",
      "Mean loss: 0.7884\n",
      "71/81\n",
      "Mean loss: 0.7856000000000001\n",
      "72/81\n",
      "Mean loss: 0.787\n",
      "73/81\n",
      "Mean loss: 0.7882\n",
      "74/81\n",
      "Mean loss: 0.7896\n",
      "75/81\n",
      "Mean loss: 0.7864\n",
      "76/81\n",
      "Mean loss: 0.7884\n",
      "77/81\n",
      "Mean loss: 0.7888000000000001\n",
      "78/81\n",
      "Mean loss: 0.7866\n",
      "79/81\n",
      "Mean loss: 0.7882\n",
      "80/81\n",
      "Mean loss: 0.7886000000000001\n",
      "test performance of initial features combination\n",
      "--------------------start greedy--------------------\n",
      "word ratio\n",
      "GRF_8\n",
      "WC_2\n",
      "GRF_3\n",
      "WC_7\n",
      "base_10\n",
      "base_9\n",
      "WC_9\n",
      "base_13\n",
      "(base_10*WC_9)\n",
      "******************** 11 round ********************\n",
      "F_feature\n",
      "0/43\n",
      "Mean loss: 0.7856\n",
      "WC_1\n",
      "1/43\n",
      "Mean loss: 0.7874000000000001\n",
      "WC_3\n",
      "2/43\n",
      "Mean loss: 0.7862\n",
      "WC_4\n",
      "3/43\n",
      "Mean loss: 0.7882\n",
      "WC_5\n",
      "4/43\n",
      "Mean loss: 0.789\n",
      "WC_6\n",
      "5/43\n",
      "Mean loss: 0.7891999999999999\n",
      "WC_8\n",
      "6/43\n",
      "Mean loss: 0.7876000000000001\n",
      "WC_10\n",
      "7/43\n",
      "Mean loss: 0.7874000000000001\n",
      "WC_11\n",
      "8/43\n",
      "Mean loss: 0.788\n",
      "WC_12\n",
      "9/43\n",
      "Mean loss: 0.7886000000000001\n",
      "WC_13\n",
      "10/43\n",
      "Mean loss: 0.7886000000000001\n",
      "WC_14\n",
      "11/43\n",
      "Mean loss: 0.7898000000000001\n",
      "WC_15\n",
      "12/43\n",
      "Mean loss: 0.7858\n",
      "WC_16\n",
      "13/43\n",
      "Mean loss: 0.7849999999999999\n",
      "WC_17\n",
      "14/43\n",
      "Mean loss: 0.784\n",
      "WC_18\n",
      "15/43\n",
      "Mean loss: 0.7874000000000001\n",
      "WC_19\n",
      "16/43\n",
      "Mean loss: 0.7876000000000001\n",
      "WC_20\n",
      "17/43\n",
      "Mean loss: 0.7884\n",
      "WC_21\n",
      "18/43\n",
      "Mean loss: 0.7888\n",
      "WC_22\n",
      "19/43\n",
      "Mean loss: 0.79\n",
      "WC_23\n",
      "20/43\n",
      "Mean loss: 0.7868\n",
      "GRF_1\n",
      "21/43\n",
      "Mean loss: 0.7886\n",
      "GRF_2\n",
      "22/43\n",
      "Mean loss: 0.7878000000000001\n",
      "GRF_4\n",
      "23/43\n",
      "Mean loss: 0.788\n",
      "GRF_5\n",
      "24/43\n",
      "Mean loss: 0.7866000000000001\n",
      "GRF_6\n",
      "25/43\n",
      "Mean loss: 0.7886\n",
      "GRF_7\n",
      "26/43\n",
      "Mean loss: 0.7906000000000001\n",
      "GRF_9\n",
      "27/43\n",
      "Mean loss: 0.7858\n",
      "GRF_10\n",
      "28/43\n",
      "Mean loss: 0.7870000000000001\n",
      "bias\n",
      "29/43\n",
      "Mean loss: 0.7874000000000001\n",
      "base_1\n",
      "30/43\n",
      "Mean loss: 0.788\n",
      "base_2\n",
      "31/43\n",
      "Mean loss: 0.7866000000000001\n",
      "base_3\n",
      "32/43\n",
      "Mean loss: 0.7904000000000001\n",
      "base_4\n",
      "33/43\n",
      "Mean loss: 0.7866\n",
      "base_5\n",
      "34/43\n",
      "Mean loss: 0.7892\n",
      "base_6\n",
      "35/43\n",
      "Mean loss: 0.7836000000000001\n",
      "base_7\n",
      "36/43\n",
      "Mean loss: 0.788\n",
      "base_8\n",
      "37/43\n",
      "Mean loss: 0.788\n",
      "base_11\n",
      "38/43\n",
      "Mean loss: 0.7868\n",
      "base_12\n",
      "39/43\n",
      "Mean loss: 0.7854000000000001\n",
      "base_14\n",
      "40/43\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean loss: 0.7858\n",
      "base_15\n",
      "41/43\n",
      "Mean loss: 0.7864000000000001\n",
      "base_16\n",
      "42/43\n",
      "Mean loss: 0.7858\n",
      "word ratio\n",
      "reverse 0/9\n",
      "Mean loss: 0.7424\n",
      "GRF_8\n",
      "reverse 1/9\n",
      "Mean loss: 0.7856\n",
      "WC_2\n",
      "reverse 2/9\n",
      "Mean loss: 0.7862\n",
      "GRF_3\n",
      "reverse 3/9\n",
      "Mean loss: 0.7708\n",
      "WC_7\n",
      "reverse 4/9\n",
      "Mean loss: 0.7852\n",
      "base_10\n",
      "reverse 5/9\n",
      "Mean loss: 0.7876000000000001\n",
      "base_9\n",
      "reverse 6/9\n",
      "Mean loss: 0.7848\n",
      "WC_9\n",
      "reverse 7/9\n",
      "Mean loss: 0.7868\n",
      "base_13\n",
      "reverse 8/9\n",
      "Mean loss: 0.7891999999999999\n",
      "--------------------complete greedy--------------------\n",
      "random select starts with:\n",
      " ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13', '(base_10*WC_9)']\n",
      " score: 0.7908\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "best score:0.7908\n",
      "best features combination: ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13', '(base_10*WC_9)']\n",
      "importance selection\n",
      "Features Quantity Limit: inf\n",
      "Time Limit: inf min(s)\n",
      "test performance of initial features combination\n",
      "remove features: baseline\n",
      "Mean loss: 0.7893999999999999\n",
      "Remove Batch: 1\n",
      "remove features: ['base_9']\n",
      "Mean loss: 0.7844\n",
      "remove features: ['base_13']\n",
      "Mean loss: 0.7864000000000001\n",
      "remove features: ['WC_9']\n",
      "Mean loss: 0.7862\n",
      "remove features: ['(base_10*WC_9)']\n",
      "Mean loss: 0.7860000000000001\n",
      "remove features: ['WC_7']\n",
      "Mean loss: 0.7772\n",
      "remove features: ['WC_2']\n",
      "Mean loss: 0.7748\n",
      "remove features: ['base_10']\n",
      "Mean loss: 0.7662\n",
      "remove features: ['GRF_8']\n",
      "Mean loss: 0.7670000000000001\n",
      "remove features: ['GRF_3']\n",
      "Mean loss: 0.7003999999999999\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "best score:0.7893999999999999\n",
      "best features combination: ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13', '(base_10*WC_9)']\n",
      "coherence selection\n",
      "Features Quantity Limit: inf\n",
      "Time Limit: inf min(s)\n",
      "test performance of initial features combination\n",
      "remove features: baseline\n",
      "Mean loss: 0.7894000000000001\n",
      "Remove Batch: 1\n",
      "totally 5 features above 0.5\n",
      "Delete WC_9 with coherence 0.6712065988721717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llls/anaconda3/envs/nlp/lib/python3.6/site-packages/MLFeatureSelection/coherence_selection.py:135: FutureWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#ix-indexer-is-deprecated\n",
      "  df.ix[i,i] = 0\n",
      "/home/llls/anaconda3/envs/nlp/lib/python3.6/site-packages/MLFeatureSelection/coherence_selection.py:89: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  tempdelete = t[t.abs().max() == t.abs().max().max()].abs().sum(axis = 1).argmax()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove features: ['WC_9']\n",
      "Mean loss: 0.7874000000000001\n",
      "Delete base_10 with coherence 0.5501168885032616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llls/anaconda3/envs/nlp/lib/python3.6/site-packages/MLFeatureSelection/coherence_selection.py:89: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  tempdelete = t[t.abs().max() == t.abs().max().max()].abs().sum(axis = 1).argmax()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove features: ['base_10']\n",
      "Mean loss: 0.7866\n",
      "Delete GRF_8 with coherence 0.515786852168539\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/llls/anaconda3/envs/nlp/lib/python3.6/site-packages/MLFeatureSelection/coherence_selection.py:89: FutureWarning: \n",
      "The current behaviour of 'Series.argmax' is deprecated, use 'idxmax'\n",
      "instead.\n",
      "The behavior of 'argmax' will be corrected to return the positional\n",
      "maximum in the future. For now, use 'series.values.argmax' or\n",
      "'np.argmax(np.array(values))' to get the position of the maximum\n",
      "row.\n",
      "  tempdelete = t[t.abs().max() == t.abs().max().max()].abs().sum(axis = 1).argmax()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "remove features: ['GRF_8']\n",
      "Mean loss: 0.7854000000000001\n",
      "*-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-**-*\n",
      "best score:0.7894000000000001\n",
      "best features combination: ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13', '(base_10*WC_9)']\n"
     ]
    }
   ],
   "source": [
    "bf = run(df, bf1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ['bias', 'word ratio', 'base_15', 'GRF_8', 'WC_2', 'GRF_1']\n",
    "2. ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'WC_22', 'base_13', '(word ratio-base_10)', '(GRF_8^WC_2)', '(GRF_3\\*base_9)', '(GRF_3-WC_2)', '(GRF_3\\*WC_2)', '(WC_7-WC_22)']\n",
    "3. ['word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9', 'WC_9', 'base_13', '(base_10\\*WC_9)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-08-17T10:04:27.630158Z",
     "start_time": "2019-08-17T10:04:27.626803Z"
    }
   },
   "outputs": [],
   "source": [
    "bf1 = [\n",
    "    'word ratio', 'GRF_8', 'WC_2', 'GRF_3', 'WC_7', 'base_10', 'base_9',\n",
    "    'WC_9', 'WC_22', 'base_13'\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Initialization Cell",
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "336.85px",
    "left": "2109px",
    "right": "20px",
    "top": "120px",
    "width": "350px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
