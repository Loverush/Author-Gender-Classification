{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T02:03:26.857806Z",
     "start_time": "2019-07-30T02:03:26.850962Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import nltk\n",
    "import re\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "### 2.1 Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Mine POS patterns\n",
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            text = gettext(txtDir + m + '/' + file)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            CorpusPOS(sentences)\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "(a, b, c, d, e) = calc_probabilities(cPOS)\n",
    "q1_output(a, b, c, d, e)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "#Feature extract\n",
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            name = txtDir + m + '/' + file\n",
    "            text = gettext(name)\n",
    "            words = getwords(text)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            words_s = split(words)\n",
    "            tags = [nltk.pos_tag(word) for word in words]\n",
    "            tags_s = split(tags)\n",
    "            words_l = wordlemmatize(tags_s)\n",
    "\n",
    "            F_feature = F_measure(tags_s)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            textTags = \"\"\n",
    "            for word, tag in tags_s:\n",
    "                if tag in tagList:\n",
    "                    textTags = textTags + tag + \" \"\n",
    "\n",
    "            POS_feature = []\n",
    "\n",
    "            for feature in posFeatures:\n",
    "                if feature in textTags:\n",
    "                    POS_feature.append(1)\n",
    "                else:\n",
    "                    POS_feature.append(0)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            POS_features.append(POS_feature)\n",
    "            labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Get single\n",
    "WC_features_l = []\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "GRF_features_l = []\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "POS_features_l = []\n",
    "for i in range(len(POS_features[0])):\n",
    "    n = i\n",
    "    POS_features_l.append(getsingle(POS_features, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Get DataFrame\n",
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(POS_features[0])):\n",
    "    key = 'POS_' + str(i + 1)\n",
    "    value = POS_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_blogs.csv', index=False)\n",
    "genderbias = pd.read_csv('blogs_genderbias.csv')\n",
    "allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    'word ratio']\n",
    "allofall.to_csv('blogs_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Word count and feature extract\n",
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "labels = []\n",
    "lengths = []\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './5000/female/'\n",
    "    else:\n",
    "        txtDir = './5000/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    handle_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(handle_gender))\n",
    "    for m in handle_gender:\n",
    "        name = txtDir + m\n",
    "        text = gettext(name)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        words_l = wordlemmatize(tags)\n",
    "\n",
    "        length = len(words)\n",
    "        F_feature = F_measure(tags)\n",
    "        GRF_feature = Gender_Preferential_Features(words_l)\n",
    "        WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "        names.append(name)\n",
    "        lengths.append(length)\n",
    "        F_features.append(F_feature)\n",
    "        GRF_features.append(GRF_feature)\n",
    "        WC_features.append(WC_feature)\n",
    "        labels.append(gender)\n",
    "\n",
    "WC_features_l = []\n",
    "GRF_features_l = []\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "map1 = {\n",
    "    'name': names,\n",
    "    'label': labels,\n",
    "    'F_feature': F_features,\n",
    "    'word count': lengths\n",
    "}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_5000.csv', index=False)\n",
    "genderbias = pd.read_csv('5000_genderbias.csv')\n",
    "allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    'word ratio']\n",
    "allofall.to_csv('5000_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['word count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T16:07:22.345141Z",
     "start_time": "2019-07-29T14:50:18.112564Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./5000/female/\n",
      "Files: 2500\n",
      "Done:500\n",
      "Done:1000\n",
      "Done:1500\n",
      "Done:2000\n",
      "Done:2500\n",
      "Processing gender: ./5000/male/\n",
      "Files: 2500\n",
      "Done:500\n",
      "Done:1000\n",
      "Done:1500\n",
      "Done:2500\n",
      "Processing gender: ./5000/female/\n",
      "Files: 2500\n",
      "Done:500\n",
      "Done:1000\n",
      "Done:1500\n",
      "Done:2000\n",
      "Processing gender: ./5000/male/\n",
      "Files: 2500\n",
      "Done:500\n",
      "Done:1000\n",
      "Done:1500\n",
      "Done:2500\n"
     ]
    }
   ],
   "source": [
    "#shorten text\n",
    "#length_list = [200, 400, 600, 800, 1200, 1600, 2000, 27850]\n",
    "length_list = [10000, 20000]\n",
    "\n",
    "for l in length_list:\n",
    "    print('\\nPresent length:{}'.format(l))\n",
    "    for gender in [0, 1]:\n",
    "        if gender == 0:\n",
    "            txtDir = './5000/female/'\n",
    "            saveDir = f'./5000-{l}/female/'\n",
    "        else:\n",
    "            txtDir = './5000/male/'\n",
    "            saveDir = f'./5000-{l}/male/'\n",
    "        if not op.isdir(f'./5000-{l}'):\n",
    "            os.mkdir(f'./5000-{l}')\n",
    "        if not op.isdir(saveDir):\n",
    "            os.mkdir(saveDir)\n",
    "        print(\"Processing gender: {}\".format(txtDir))\n",
    "        handle_gender = os.listdir(txtDir)\n",
    "        print(\"Files:\", len(handle_gender))\n",
    "        for idx, m in enumerate(handle_gender):\n",
    "            name = txtDir + m\n",
    "            text = gettext(name)\n",
    "            words = nltk.word_tokenize(text)\n",
    "            if len(words) < (l + 1):\n",
    "                continue\n",
    "            words = words[:l]\n",
    "            text = ''\n",
    "            for word in words:\n",
    "                text = text + word + ' '\n",
    "            with open(op.join(saveDir, m), 'w') as f:\n",
    "                f.write(text)\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('Done:{}'.format(idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:12:14.292892Z",
     "start_time": "2019-07-30T02:03:32.744562Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/2104 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Present length:20000\n",
      "Processing gender: ./5000-20000/female/\n",
      "Files: 2104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2104/2104 [34:57<00:00,  1.12it/s]\n",
      "  0%|          | 0/1954 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./5000-20000/male/\n",
      "Files: 1954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1954/1954 [33:43<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "#feature extract\n",
    "length_list = [10000, 20000]\n",
    "for l in length_list:\n",
    "    names = []\n",
    "    F_features = []\n",
    "    GRF_features = []\n",
    "    WC_features = []\n",
    "    labels = []\n",
    "    print('\\nPresent length:{}'.format(l))\n",
    "    for gender in [0, 1]:\n",
    "        if gender == 0:\n",
    "            txtDir = f'./5000-{l}/female/'\n",
    "        else:\n",
    "            txtDir = f'./5000-{l}/male/'\n",
    "\n",
    "        print(\"Processing gender: {}\".format(txtDir))\n",
    "        handle_gender = os.listdir(txtDir)\n",
    "        print(\"Files:\", len(handle_gender))\n",
    "        for m in tqdm(handle_gender):\n",
    "            name = txtDir + m\n",
    "            text = gettext(name)\n",
    "            words = nltk.word_tokenize(text)\n",
    "            tags = nltk.pos_tag(words)\n",
    "            words_l = wordlemmatize(tags)\n",
    "\n",
    "            F_feature = F_measure(tags)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            labels.append(gender)\n",
    "\n",
    "    WC_features_l = []\n",
    "    GRF_features_l = []\n",
    "\n",
    "    for i in range(len(WC_features[0])):\n",
    "        n = i\n",
    "        WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "    for i in range(len(GRF_features[0])):\n",
    "        n = i\n",
    "        GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "    map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "    for i in range(len(WC_features[0])):\n",
    "        key = 'WC_' + str(i + 1)\n",
    "        value = WC_features_l[i]\n",
    "        map1[key] = value\n",
    "\n",
    "    for i in range(len(GRF_features[0])):\n",
    "        key = 'GRF_' + str(i + 1)\n",
    "        value = GRF_features_l[i]\n",
    "        map1[key] = value\n",
    "\n",
    "    allofall = pd.DataFrame(map1)\n",
    "\n",
    "    F_features_u = np.array(F_features)\n",
    "    F_features_u = (F_features_u -\n",
    "                    np.mean(F_features_u)) / np.std(F_features_u)\n",
    "    allofall['F_feature'] = F_features_u\n",
    "\n",
    "    allofall.to_csv(f'allofall_5000-{l}.csv', index=False)\n",
    "    #genderbias = pd.read_csv(f'5000-{l}_genderbias.csv')\n",
    "    #allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias['word ratio']\n",
    "    #allofall.to_csv(f'5000-{l}_features.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:27:59.311878Z",
     "start_time": "2019-07-30T03:27:12.590772Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Length:10000\n",
      "All features:\n",
      "[0.75       0.76777778 0.77641824 0.76195773 0.76751947]\n",
      "Accuracy: 0.76 (+/- 0.02)\n",
      "Without Gender bias:\n",
      "[0.72111111 0.74777778 0.73859844 0.73081201 0.71746385]\n",
      "Accuracy: 0.73 (+/- 0.02)\n",
      "Gender bias:\n",
      "[0.69222222 0.70555556 0.7163515  0.71968854 0.72080089]\n",
      "Accuracy: 0.71 (+/- 0.02)\n",
      "\n",
      " Length:20000\n",
      "All features:\n",
      "[0.78448276 0.77216749 0.76108374 0.79064039 0.77037037]\n",
      "Accuracy: 0.78 (+/- 0.02)\n",
      "Without Gender bias:\n",
      "[0.75492611 0.73891626 0.73522167 0.77955665 0.75061728]\n",
      "Accuracy: 0.75 (+/- 0.03)\n",
      "Gender bias:\n",
      "[0.71921182 0.70197044 0.70935961 0.72536946 0.7345679 ]\n",
      "Accuracy: 0.72 (+/- 0.02)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "allf = []\n",
    "allf_i = []\n",
    "gb = []\n",
    "gb_i = []\n",
    "without = []\n",
    "without_i = []\n",
    "featurelist = []\n",
    "length_list = [10000, 20000]\n",
    "for l in length_list:\n",
    "    allofall = pd.read_csv(f'5000-{l}_features.csv')\n",
    "    #genderbias = pd.read_csv(f'5000-{l}_genderbias.csv')\n",
    "    #allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    #    'word ratio']\n",
    "    data, target = allofall.drop(\n",
    "        columns=['name', 'label']).iloc[:].values, allofall['label'].values\n",
    "    train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                        target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    data, target = pd.concat(\n",
    "        (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "            (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "    data1 = data.iloc[:, :-2]\n",
    "    data2 = data.iloc[:, -2:]\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                     max_leaf_nodes=50,\n",
    "                                     n_jobs=-1)\n",
    "\n",
    "    rnd_clf.fit(data.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('\\n Length:{}'.format(l))\n",
    "    print('All features:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    allf.append(scores_rnd_clf_cv.mean())\n",
    "    allf_i.append([rnd_clf.feature_importances_])\n",
    "\n",
    "    rnd_clf.fit(data1.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data1.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Without Gender bias:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    without.append(scores_rnd_clf_cv.mean())\n",
    "    without_i.append([rnd_clf.feature_importances_])\n",
    "\n",
    "    rnd_clf.fit(data2.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data2.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Gender bias:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    gb.append(scores_rnd_clf_cv.mean())\n",
    "    gb_i.append([rnd_clf.feature_importances_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-30T03:34:17.308245Z",
     "start_time": "2019-07-30T03:34:17.297237Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "#length vs accuracy\n",
    "df = pd.read_csv('top5_sum_all.csv')\n",
    "df = df.set_index('length')\n",
    "\n",
    "allf_ii = [0, 0]\n",
    "without_ii = [0, 0]\n",
    "gb_ii = [0, 0]\n",
    "name = allofall.columns[:-2]\n",
    "for i in range(2):\n",
    "    allf_ii[i] = sorted(list(zip(name, allf_i[i][0])),\n",
    "                        key=lambda x: x[1],\n",
    "                        reverse=True)\n",
    "    without_ii[i] = sorted(list(zip(name[:-2], without_i[i][0])),\n",
    "                           key=lambda x: x[1],\n",
    "                           reverse=True)\n",
    "    gb_ii[i] = sorted(list(zip(name[-2:], gb_i[i][0])),\n",
    "                      key=lambda x: x[1],\n",
    "                      reverse=True)\n",
    "\n",
    "allf_iii = [0, 0]\n",
    "without_iii = [0, 0]\n",
    "name = ['F', 'WC', 'GRF', 'bias', 'word ratio']\n",
    "for i in range(2):\n",
    "    temp = allf_i[i]\n",
    "    handle = [0] * 5\n",
    "    handle[0] = temp[0][0]\n",
    "    handle[1] = sum(temp[0][1:24])\n",
    "    handle[2] = sum(temp[0][24:34])\n",
    "    handle[3:] = temp[0][-2:]\n",
    "    handle = sorted(zip(name, handle), key=lambda x: x[1], reverse=True)\n",
    "    allf_iii[i] = handle\n",
    "    temp = without_i[i]\n",
    "    handle = [0] * 3\n",
    "    handle[0] = temp[0][0]\n",
    "    handle[1] = sum(temp[0][1:24])\n",
    "    handle[2] = sum(temp[0][24:34])\n",
    "    handle = sorted(zip(name[:-2], handle), key=lambda x: x[1], reverse=True)\n",
    "    without_iii[i] = handle\n",
    "\n",
    "for i in range(2):\n",
    "    df.iloc[7 + i, 0] = allf[i]\n",
    "    df.iloc[7 + i, 3] = without[i]\n",
    "    df.iloc[7 + i, 6] = gb[i]\n",
    "    df.iloc[7 + i, 1] = [allf_ii[i]]\n",
    "    df.iloc[7 + i, 4] = [without_ii[i]]\n",
    "    df.iloc[7 + i, 7] = [gb_ii[i]]\n",
    "    df.iloc[7 + i, 2] = [allf_iii[i]]\n",
    "    df.iloc[7 + i, 5] = [without_iii[i]]\n",
    "#df.to_csv('top5_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#10wincv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for i in range(1, 11):\n",
    "    fname = str(10 + i) + '_win_5000_genderbias.csv'\n",
    "    genderbias = pd.read_csv(fname)\n",
    "    allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "        'word ratio']\n",
    "    data, target = allofall.drop(columns=['name', 'label', 'word count']\n",
    "                                 ).iloc[:].values, allofall['label'].values\n",
    "    train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                        target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    data, target = pd.concat(\n",
    "        (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "            (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=1000,\n",
    "                                     max_leaf_nodes=50,\n",
    "                                     n_jobs=-1)\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Windows:%.2f'%(i))\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "316.85px",
    "left": "1418px",
    "right": "50px",
    "top": "120px",
    "width": "317px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
