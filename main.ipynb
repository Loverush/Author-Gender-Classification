{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:43:08.601889Z",
     "start_time": "2019-07-29T01:43:08.018069Z"
    },
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as op\n",
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "import sklearn\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from func import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Feature Engineering\n",
    "### 2.1 Blogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Mine POS patterns\n",
    "tagList = [\n",
    "    'NN', 'CC', 'LS', 'PDT', 'POS', 'SYM', 'NNS', 'NNP', 'NNPS', 'FW', 'CD',\n",
    "    'JJ', 'JJR', 'JJS', 'IN', 'TO', 'DT', 'EX', 'PRP', 'PRP$', 'WDT', 'WP',\n",
    "    'WP$', 'MD', 'VB', 'VBZ', 'VBP', 'VBD', 'VBN', 'VBG', 'RB', 'RBR', 'RBS',\n",
    "    'RP', 'WRB', 'UH', '.'\n",
    "]\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            text = gettext(txtDir + m + '/' + file)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            CorpusPOS(sentences)\n",
    "\n",
    "infile = open('CorpusPOS.txt', 'r')\n",
    "cPOS = infile.readlines()\n",
    "infile.close()\n",
    "(a, b, c, d, e) = calc_probabilities(cPOS)\n",
    "q1_output(a, b, c, d, e)\n",
    "\n",
    "Prob = {}\n",
    "infile = open('probabilities.txt', 'r')\n",
    "prob_text = infile.readlines()\n",
    "\n",
    "for sentence in prob_text:\n",
    "    keyValPair = sentence.split(\":\")\n",
    "    Prob[keyValPair[0]] = float(keyValPair[1][:-1])\n",
    "\n",
    "infile.close()\n",
    "\n",
    "posFeatures = minePOSPats(cPOS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0,
     8
    ]
   },
   "outputs": [],
   "source": [
    "#Feature extract\n",
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "POS_features = []\n",
    "labels = []\n",
    "\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './postprocess_blogs/blogs/female/'\n",
    "    else:\n",
    "        txtDir = './postprocess_blogs/blogs/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    blogs_gender = os.listdir(txtDir)\n",
    "    for i in range(0, len(blogs_gender)):\n",
    "        m = blogs_gender[i]\n",
    "        print(\"Processing: \", m)\n",
    "        print(\"Files:\", len(os.listdir(txtDir + m)))\n",
    "        for file in os.listdir(txtDir + m):\n",
    "            name = txtDir + m + '/' + file\n",
    "            text = gettext(name)\n",
    "            words = getwords(text)\n",
    "            sentences = nltk.sent_tokenize(text)\n",
    "            words_s = split(words)\n",
    "            tags = [nltk.pos_tag(word) for word in words]\n",
    "            tags_s = split(tags)\n",
    "            words_l = wordlemmatize(tags_s)\n",
    "\n",
    "            F_feature = F_measure(tags_s)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            textTags = \"\"\n",
    "            for word, tag in tags_s:\n",
    "                if tag in tagList:\n",
    "                    textTags = textTags + tag + \" \"\n",
    "\n",
    "            POS_feature = []\n",
    "\n",
    "            for feature in posFeatures:\n",
    "                if feature in textTags:\n",
    "                    POS_feature.append(1)\n",
    "                else:\n",
    "                    POS_feature.append(0)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            POS_features.append(POS_feature)\n",
    "            labels.append(gender)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Get single\n",
    "def getsingle(features, n):\n",
    "    single = []\n",
    "    for item in features:\n",
    "        single.append(item[n])\n",
    "    return single\n",
    "\n",
    "\n",
    "WC_features_l = []\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "GRF_features_l = []\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "POS_features_l = []\n",
    "for i in range(len(POS_features[0])):\n",
    "    n = i\n",
    "    POS_features_l.append(getsingle(POS_features, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Get DataFrame\n",
    "map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(POS_features[0])):\n",
    "    key = 'POS_' + str(i + 1)\n",
    "    value = POS_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_blogs.csv', index=False)\n",
    "genderbias = pd.read_csv('blogs_genderbias.csv')\n",
    "allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    'word ratio']\n",
    "allofall.to_csv('blogs_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Novels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#Word count and feature extract\n",
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "labels = []\n",
    "lengths = []\n",
    "for gender in [0, 1]:\n",
    "    if gender == 0:\n",
    "        txtDir = './5000/female/'\n",
    "    else:\n",
    "        txtDir = './5000/male/'\n",
    "\n",
    "    print(\"Processing gender: {}\".format(txtDir))\n",
    "    handle_gender = os.listdir(txtDir)\n",
    "    print(\"Files:\", len(handle_gender))\n",
    "    for m in handle_gender:\n",
    "        name = txtDir + m\n",
    "        text = gettext(name)\n",
    "        words = nltk.word_tokenize(text)\n",
    "        tags = nltk.pos_tag(words)\n",
    "        words_l = wordlemmatize(tags)\n",
    "\n",
    "        length = len(words)\n",
    "        F_feature = F_measure(tags)\n",
    "        GRF_feature = Gender_Preferential_Features(words_l)\n",
    "        WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "        names.append(name)\n",
    "        lengths.append(length)\n",
    "        F_features.append(F_feature)\n",
    "        GRF_features.append(GRF_feature)\n",
    "        WC_features.append(WC_feature)\n",
    "        labels.append(gender)\n",
    "\n",
    "WC_features_l = []\n",
    "GRF_features_l = []\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    n = i\n",
    "    WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    n = i\n",
    "    GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "map1 = {\n",
    "    'name': names,\n",
    "    'label': labels,\n",
    "    'F_feature': F_features,\n",
    "    'word count': lengths\n",
    "}\n",
    "\n",
    "for i in range(len(WC_features[0])):\n",
    "    key = 'WC_' + str(i + 1)\n",
    "    value = WC_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "for i in range(len(GRF_features[0])):\n",
    "    key = 'GRF_' + str(i + 1)\n",
    "    value = GRF_features_l[i]\n",
    "    map1[key] = value\n",
    "\n",
    "allofall = pd.DataFrame(map1)\n",
    "\n",
    "F_features_u = np.array(F_features)\n",
    "F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "allofall['F_feature'] = F_features_u\n",
    "\n",
    "allofall.to_csv('allofall_5000.csv', index=False)\n",
    "genderbias = pd.read_csv('5000_genderbias.csv')\n",
    "allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    'word ratio']\n",
    "allofall.to_csv('5000_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allofall['word count'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-24T16:46:39.525778Z",
     "start_time": "2019-07-24T16:05:30.227918Z"
    },
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#shorten text\n",
    "length_list = [200, 400, 600, 800, 1200, 1600, 2000, 27850]\n",
    "\n",
    "for l in length_list:\n",
    "    for gender in [0, 1]:\n",
    "        if gender == 0:\n",
    "            txtDir = './5000/female/'\n",
    "            saveDir = f'./5000-{l}/female/'\n",
    "        else:\n",
    "            txtDir = './5000/male/'\n",
    "            saveDir = f'./5000-{l}/male/'\n",
    "        print(\"Processing gender: {}\".format(txtDir))\n",
    "        handle_gender = os.listdir(txtDir)\n",
    "        print(\"Files:\", len(handle_gender))\n",
    "        for idx, m in enumerate(handle_gender):\n",
    "            name = txtDir + m\n",
    "            text = gettext(name)\n",
    "            words = nltk.word_tokenize(text)\n",
    "            if len(words) < (l + 1):\n",
    "                continue\n",
    "            words = words[:l]\n",
    "            text = ''\n",
    "            for word in words:\n",
    "                text = text + word + ' '\n",
    "            with open(op.join(saveDir, m), 'w') as f:\n",
    "                f.write(text)\n",
    "            if (idx + 1) % 500 == 0:\n",
    "                print('Done:{}'.format(idx + 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-25T06:33:02.312764Z",
     "start_time": "2019-07-25T06:24:29.575400Z"
    },
    "code_folding": [
     0
    ],
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing gender: ./5000-1600/female/\n",
      "Files: 2468\n",
      "Processing gender: ./5000-1600/male/\n",
      "Files: 2456\n"
     ]
    }
   ],
   "source": [
    "#feature extract\n",
    "names = []\n",
    "F_features = []\n",
    "GRF_features = []\n",
    "WC_features = []\n",
    "labels = []\n",
    "\n",
    "\n",
    "for l in length_list:\n",
    "    for gender in [0, 1]:\n",
    "        if gender == 0:\n",
    "            txtDir = f'./5000-{l}/female/'\n",
    "        else:\n",
    "            txtDir = f'./5000-{l}/male/'\n",
    "\n",
    "        print(\"Processing gender: {}\".format(txtDir))\n",
    "        handle_gender = os.listdir(txtDir)\n",
    "        print(\"Files:\", len(handle_gender))\n",
    "        for m in handle_gender:\n",
    "            name = txtDir + m\n",
    "            text = gettext(name)\n",
    "            words = nltk.word_tokenize(text)\n",
    "            tags = nltk.pos_tag(words)\n",
    "            words_l = wordlemmatize(tags)\n",
    "\n",
    "            F_feature = F_measure(tags)\n",
    "            GRF_feature = Gender_Preferential_Features(words_l)\n",
    "            WC_feature = Word_Classes_Feature(words_l)\n",
    "\n",
    "            names.append(name)\n",
    "            F_features.append(F_feature)\n",
    "            GRF_features.append(GRF_feature)\n",
    "            WC_features.append(WC_feature)\n",
    "            labels.append(gender)\n",
    "\n",
    "    WC_features_l = []\n",
    "    GRF_features_l = []\n",
    "\n",
    "    for i in range(len(WC_features[0])):\n",
    "        n = i\n",
    "        WC_features_l.append(getsingle(WC_features, n))\n",
    "\n",
    "    for i in range(len(GRF_features[0])):\n",
    "        n = i\n",
    "        GRF_features_l.append(getsingle(GRF_features, n))\n",
    "\n",
    "    map1 = {'name': names, 'label': labels, 'F_feature': F_features}\n",
    "\n",
    "    for i in range(len(WC_features[0])):\n",
    "        key = 'WC_' + str(i + 1)\n",
    "        value = WC_features_l[i]\n",
    "        map1[key] = value\n",
    "\n",
    "    for i in range(len(GRF_features[0])):\n",
    "        key = 'GRF_' + str(i + 1)\n",
    "        value = GRF_features_l[i]\n",
    "        map1[key] = value\n",
    "\n",
    "    allofall = pd.DataFrame(map1)\n",
    "\n",
    "    F_features_u = np.array(F_features)\n",
    "    F_features_u = (F_features_u - np.mean(F_features_u)) / np.std(F_features_u)\n",
    "    allofall['F_feature'] = F_features_u\n",
    "\n",
    "    allofall.to_csv(f'allofall_5000-{l}.csv',index = False)\n",
    "    genderbias = pd.read_csv(f'5000-{l}_genderbias.csv')\n",
    "    allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias['word ratio']\n",
    "    allofall.to_csv(f'5000-{l}_features.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-29T01:51:59.077380Z",
     "start_time": "2019-07-29T01:51:35.556693Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Length:2000\n",
      "All features:\n",
      "[0.75914634 0.75788403 0.74439919 0.74541752 0.76374745]\n",
      "Accuracy: 0.75 (+/- 0.02)\n",
      "Without Gender bias:\n",
      "[0.69613821 0.70803662 0.68940937 0.71181263 0.71384929]\n",
      "Accuracy: 0.70 (+/- 0.02)\n",
      "Gender bias:\n",
      "[0.70833333 0.7456765  0.71792261 0.70875764 0.71995927]\n",
      "Accuracy: 0.72 (+/- 0.03)\n"
     ]
    }
   ],
   "source": [
    "#train\n",
    "allf = []\n",
    "allf_i = []\n",
    "gb = []\n",
    "gb_i = []\n",
    "without = []\n",
    "without_i = []\n",
    "featurelist = []\n",
    "\n",
    "for l in length_list:\n",
    "    allofall = pd.read_csv(f'5000-{l}_features.csv')\n",
    "    #genderbias = pd.read_csv(f'5000-{l}_genderbias.csv')\n",
    "    #allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "    #    'word ratio']\n",
    "    data, target = allofall.drop(\n",
    "        columns=['name', 'label']).iloc[:].values, allofall['label'].values\n",
    "    train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                        target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    data, target = pd.concat(\n",
    "        (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "            (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "    data1 = data.iloc[:, :-2]\n",
    "    data2 = data.iloc[:, -2:]\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=800,\n",
    "                                     max_leaf_nodes=64,\n",
    "                                     n_jobs=-1)\n",
    "\n",
    "    rnd_clf.fit(data.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('\\n Length:{}'.format(l))\n",
    "    print('All features:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    allf.append(scores_rnd_clf_cv.mean())\n",
    "    allf_i.append([rnd_clf.feature_importances_])\n",
    "\n",
    "    rnd_clf.fit(data1.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data1.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Without Gender bias:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    without.append(scores_rnd_clf_cv.mean())\n",
    "    without_i.append([rnd_clf.feature_importances_])\n",
    "\n",
    "    rnd_clf.fit(data2.values, target.values.reshape(-1, ))\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data2.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Gender bias:')\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))\n",
    "    gb.append(scores_rnd_clf_cv.mean())\n",
    "    gb_i.append([rnd_clf.feature_importances_])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T00:23:36.353317Z",
     "start_time": "2019-07-27T00:23:36.342696Z"
    }
   },
   "outputs": [],
   "source": [
    "#length vs accuracy\n",
    "df = pd.DataFrame({'length':length_list,\n",
    "                  'All features':allf,\n",
    "                   'All features_importances':allf_i_new,\n",
    "                  'Without gb':without,\n",
    "                   'Without gb_importances':without_i_new,\n",
    "                  'Gender bias':gb,\n",
    "                  'Gender bias_importances':gb_i_new})\n",
    "df = df.set_index('length')\n",
    "#df.to_csv('top5_sum.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Others"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": [
     0
    ],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#10wincv\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "for i in range(1, 11):\n",
    "    fname = str(10 + i) + '_win_5000_genderbias.csv'\n",
    "    genderbias = pd.read_csv(fname)\n",
    "    allofall['bias'], allofall['word ratio'] = genderbias['bias'], genderbias[\n",
    "        'word ratio']\n",
    "    data, target = allofall.drop(columns=['name', 'label', 'word count']\n",
    "                                 ).iloc[:].values, allofall['label'].values\n",
    "    train_X, test_X, train_y, test_y = train_test_split(data,\n",
    "                                                        target,\n",
    "                                                        test_size=0.2,\n",
    "                                                        random_state=42,\n",
    "                                                        shuffle=True)\n",
    "    data, target = pd.concat(\n",
    "        (pd.DataFrame(train_X), pd.DataFrame(test_X))), pd.concat(\n",
    "            (pd.DataFrame(train_y), pd.DataFrame(test_y)))\n",
    "\n",
    "    rnd_clf = RandomForestClassifier(n_estimators=1000,\n",
    "                                     max_leaf_nodes=50,\n",
    "                                     n_jobs=-1)\n",
    "    scores_rnd_clf_cv = cross_val_score(rnd_clf,\n",
    "                                        data.values,\n",
    "                                        target.values.reshape(-1, ),\n",
    "                                        cv=5)\n",
    "    print('Windows:%.2f'%(i))\n",
    "    print(scores_rnd_clf_cv)\n",
    "    print(\"Accuracy: %0.2f (+/- %0.2f)\" %\n",
    "          (scores_rnd_clf_cv.mean(), scores_rnd_clf_cv.std() * 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T15:25:25.073197Z",
     "start_time": "2019-07-27T15:25:25.063966Z"
    }
   },
   "outputs": [],
   "source": [
    "m = {'F_feature': 0.06774622830146265, 'WC_1': 0.030750302311476855, 'WC_2': 0.05194608467327763, 'WC_3': 0.04181383957225258, 'WC_4': 0.042101931752933544, 'WC_5': 0.01859543308878391, 'WC_6': 0.006798851770971471, 'WC_7': 0.029499780289836085, 'WC_8': 0.016370913051504194, 'WC_9': 0.017484348718995835, 'WC_10': 0.027083945643367267, 'WC_11': 0.023206040153359947, 'WC_12': 0.01985475337506297, 'WC_13': 0.027982606161854492, 'WC_14': 0.0198331507264329, 'WC_15': 0.07211366178386407, 'WC_16': 0.004959599670063322, 'WC_17': 0.04699624733726917, 'WC_18': 0.0103817547431019, 'WC_19': 0.008637290754813388, 'WC_20': 0.02385450240258374, 'WC_21': 0.017809444504190624, 'WC_22': 0.014857432338504355, 'WC_23': 0.01861932381502889, 'GRF_1': 0.00984362622705038, 'GRF_2': 0.1188716568744626, 'GRF_3': 0.07429039446230534, 'GRF_4': 0.006839419658838325, 'GRF_5': 0.01373370302145265, 'GRF_6': 0.014094758264402284, 'GRF_7': 0.007359464148519862, 'GRF_8': 0.07731371783211263, 'GRF_9': 0.0165323457001773, 'GRF_10': 0.0018234468696868434}\n",
    "m = sorted(m.items(),key=lambda x:x[1],reverse=True)\n",
    "m = m[:5]\n",
    "ms.append(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T16:21:08.372872Z",
     "start_time": "2019-07-28T16:21:08.369728Z"
    }
   },
   "outputs": [],
   "source": [
    "name = allofall.columns[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T16:21:44.444321Z",
     "start_time": "2019-07-28T16:21:44.437856Z"
    }
   },
   "outputs": [],
   "source": [
    "i = without_i[1]\n",
    "handle = [0]*5\n",
    "handle[0]= i[0][0]\n",
    "handle[1]=sum(i[0][1:24])\n",
    "handle[2]=sum(i[0][24:34])\n",
    "handle[3:]=i[0][-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-28T16:21:33.887859Z",
     "start_time": "2019-07-28T16:21:33.884304Z"
    }
   },
   "outputs": [],
   "source": [
    "name = ['F','WC','GRF','bias','word ratio']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:24:53.646253Z",
     "start_time": "2019-07-27T16:24:53.642521Z"
    }
   },
   "outputs": [],
   "source": [
    "sum33 = []\n",
    "for i in sum2:\n",
    "    sum33.append(list(zip(flist,i)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:05:01.539026Z",
     "start_time": "2019-07-27T16:05:01.533242Z"
    }
   },
   "outputs": [],
   "source": [
    "df.insert(2,'All features sum_importances',sum11)\n",
    "df.insert(5,'Without gb sum_importances',sum22)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:25:06.127943Z",
     "start_time": "2019-07-27T16:25:06.123314Z"
    }
   },
   "outputs": [],
   "source": [
    "df.iloc[:,2] = sum33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-07-27T16:16:30.221469Z",
     "start_time": "2019-07-27T16:16:30.216393Z"
    }
   },
   "outputs": [],
   "source": [
    "sum22 = []\n",
    "for i in sum33:\n",
    "    sum22.append(list(sorted(i,key=lambda x:x[1],reverse=True))[:5])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "nlp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "316.85px",
    "left": "1418px",
    "right": "50px",
    "top": "120px",
    "width": "317px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
